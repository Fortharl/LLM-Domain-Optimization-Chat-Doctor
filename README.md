# LLM Domain Optimization (Prompt Engineering / RAG / PEFT)

## Overview

Данный репозиторий представляет собой исследовательский R&D-проект по адаптации компактной языковой модели (Qwen2.5-3B) к специализированной доменной задаче — медицинскому консультированию. Работа направлена на изучение управляемости генерации, клинической логики, безопасности и эффективности малых LLM при ограниченных вычислительных ресурсах.

Исследование охватывает полный цикл: подготовку корпуса, параметро-эффективное дообучение (QLoRA), построение retrieval-архитектуры (RAG), подбор промптов, анализ поведения всех систем и количественную оценку качества.

---

## Research Objectives

- Проверить возможность адаптации малой LLM к медицинскому стилю консультации  
- Оценить влияние качества данных на безопасность и поведение модели  
- Сравнить Base / Prompt / QLoRA / RAG архитектуры  
- Исследовать компромисс **Latency vs Clinical Quality**  
- Проанализировать failure modes генерации  
- Оценить эффективность PEFT при ограниченных ресурсах  

---

## Scope of Work

### PEFT

#### Data Engineering
- Формирование QA-корпуса из Doctor-HealthCare-100k
- Построение двух независимых датасетов:
  - **RAW** — без фильтрации
  - **Cleaned** — двухэтапная очистка (Удаление дублей и шумовых токенов / Нормализация медицинского стиля)

#### Model Adaptation
- Дообучение **Qwen-3B** через QLoRA (PEFT)
- Обучение на двух версиях корпуса
- Анализ поведения адаптеров
- Исследование устойчивости генерации

### RAG Architecture
- Построение локального RAG-pipeline
- Стек: HuggingFaceEmbeddings, FAISS, mlx_lm
- Создание FAISS индекса из медицинского справочника
- Реализация Retrieval (семантический поиск) и локальной Generation через MLX 

### Prompt Engineering
- Использовался как вспомогательный инструмент (minor contribution)

### Evaluation
- Эксперименты:
  - Base
  - QLoRA
  - Base + RAG
  - QLoRA + RAG
- LLM-as-a-Judge оценка
- Анализ галлюцинаций
- Проверка безопасности
- Token efficiency
- Red-Flag detection
- Сравнительный behavioral analysis

---

## Training Setup

**Base Model:** Qwen-3B  
**Method:** QLoRA (PEFT)  
**Hardware:** Colab T4  
**Libraries:**  
- transformers  
- peft  
- trl  
- bitsandbytes  

**Training Size:** 1000 QA  
**Experiments:** RAW vs Cleaned dataset  

---

## QLoRA Adapter Analysis

### RAW_DATA_QLoRA

Обучен на неочищенном корпусе.

Наблюдаемое поведение:
- Наследование шумового стиля исходного корпуса
- Галлюцинации
- Рискованные назначения
- Циклическая генерация
- Слабая управляемость

---

### Cleaned_DATA_QLoRA

Обучен на очищенном корпусе.

Наблюдаемое поведение:
- Клиническая структура ответа  
  *(Причина → Диагностика → Маршрутизация)*
- Минимальные галлюцинации
- Безопасная стратегия
- Высокая token-эффективность
- Поведение ближе к doctor_answer

---

## Quantitative Comparison (LLM-Judge)

| Metric | Base | RAW QLoRA | Cleaned QLoRA |
|--------|------|-----------|---------------|
| Accuracy | 3.9 | 2.1 | **4.4** |
| Safety | 4.5 | 3.0 | **4.8** |
| Relevance | 3.8 | 1.8 | **4.6** |
| Usefulness | 3.8 | 2.4 | **4.2** |
| Avg Tokens | 280 | 320 | **90** |

**Key Result:** качество корпуса напрямую влияет на безопасность и управляемость модели.

---
## <font color="#1F618D"><u>Основные инсайты исследования</u></font>

На основе анализа метрик и сгенерированных ответов выделены следующие ключевые закономерности:

* **RAG — гарант безопасности:** Применение RAG (Retrieval-Augmented Generation) является критически важным для медицинской безопасности. Оценка выявления <font color="#C0392B">**Red Flags**</font> возрастает более чем в 2 раза (с **2.36** до **4.49**).
* **ИИ против Человека:** В данной выборке модели ИИ (особенно Base + RAG) превзошли «эталонные» ответы врачей по клинической точности и полноте плана действий. Это объясняется тем, что реальные ответы врачей часто были слишком краткими и игнорировали предупреждения о рисках.
* **Скорость против Качества:** Тонкая настройка (**QLoRA**) значительно ускоряет генерацию (в 3-5 раз), но ведет к деградации способности модели распознавать критические ситуации. Это объясняется перениманием поведения из обучающей выборки на ответах врачей.
* **Стиль и лаконичность:** Модели QLoRA лучше имитируют стиль «быстрого чата», в то время как базовые модели склонны к избыточности, если не ограничен системный промпт.

---

### <font color="#1F618D"><u>Сравнительная таблица метрик</u></font>

В таблице представлены усредненные значения для ключевых конфигураций.
| Модель* | Latency (s) | Prompt | Generated | Total | Clinical correctness & factual accuracy | Appropriate triage & urgency guidance | Safety | Differential diagnosis quality | Actionability | <font color="#C0392B">Red Flags</font> | Communication quality |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **Doctor Answer** | — | — | — | — | 3.41 | 3.24 | 3.47 | 2.64 | 3.22 | 1.68 | 3.30 |
| **Base Qwen3B** | 7.79 | 129.3 | 327.2 | 456.5 | 4.01 | 4.17 | 4.37 | 3.47 | 3.99 | 2.36 | 4.54 |
| **Base + SysPrompt** | 8.01 | 448.3 | 295.2 | 743.6 | 3.85 | 3.91 | 4.15 | 3.13 | 3.55 | 2.08 | 4.53 |
| <font color="#21618C">**Base + RAG**</font> | <font color="#7B241C">12.01</font> | 341.6 | 478.3 | 819.8 | **3.99** | **4.53** | **4.70** | **3.54** | **4.60** | **4.49** | **4.85** |
| **Base + Sys+RAG** | 7.90 | 549.6 | 271.1 | 820.6 | 3.78 | 3.92 | 4.09 | 2.95 | 3.46 | 2.11 | 4.47 |
| <font color="#1D8348">**Cleaned QLoRA**</font> | **2.38** * | 129.3 | **85.5** | **214.9** | 3.52 | 3.23 | 3.80 | 2.53 | 2.90 | <font color="#7B241C">1.26</font> | 3.43 |
| **QLoRA + SysPrompt** | 4.44 | 448.3 | 154.9 | 603.2 | 3.70 | 3.55 | 3.97 | 2.87 | 3.33 | 1.28 | 3.96 |
| **QLoRA + RAG** | 5.36 | 685.6 | 176.3 | 861.9 | 3.62 | 3.77 | 4.07 | 2.86 | 3.49 | 2.24 | 3.78 |
| **QLoRA + Sys+RAG** | 4.31 | 549.6 | 144.0 | 693.6 | 3.44 | 3.41 | 3.77 | 2.57 | 2.90 | 1.33 | 3.62 |

\*Все модели в INT8
**Низкая Latency за счет "выученной" через адаптер краткости.
