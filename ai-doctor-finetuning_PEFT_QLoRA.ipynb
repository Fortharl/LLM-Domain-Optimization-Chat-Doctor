{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Работа с данным ноутбуком проводилась в Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "27kfLkVsemMk",
    "outputId": "e2a978e5-2557-4306-871f-9ed81ded2177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.26.2-py3-none-any.whl (518 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets, bitsandbytes, trl, peft\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.18.0\n",
      "    Uninstalling peft-0.18.0:\n",
      "      Successfully uninstalled peft-0.18.0\n",
      "Successfully installed bitsandbytes-0.49.1 datasets-4.4.2 peft-0.18.1 pyarrow-22.0.0 trl-0.26.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "2b8378b2d29c4e218103bddb3fb536ba",
       "pip_warning": {
        "packages": [
         "datasets",
         "pyarrow"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U bitsandbytes transformers accelerate peft datasets trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrSHNyaZeE_Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3uCQp3JQg2G"
   },
   "source": [
    "# Обучение адаптера на исходный QA данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "BwQq7WNXfBIa",
    "outputId": "6f2d45c1-314b-4b29-cb8b-1bba05b6e36b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1daa94a9-035e-43ca-a444-a44190d8f410\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1daa94a9-035e-43ca-a444-a44190d8f410\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Doctor-HealthCare-100k.csv to Doctor-HealthCare-100k.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Загрузка файла с локального ПК\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "LoESw8vssZwH",
    "outputId": "440263e9-af39-4f5c-bcf9-d343c2a6e531"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"If you are a doctor, please answer the medical questions based on the patient's description.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Hi , I m 17 years old. Me and my bf had sex on Saturday we used protection. Afterward I gave him oral till he came then about 20 mins after he came , he inserted his penis in me for about 8 second then took it out . What are my chance of getting pregnant ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 997,\n        \"samples\": [\n          \"Hi! Thanks for sharing your sons' health problem with us! Well, if were your family physician for this case of neck lump with symptoms of sore throat, aching neck and loss of appetite, I would like to first confirm the diagnosis and for this I would suggest Ultrasound and a simple needle biopsy from the said lump; then I decide the line of treatment accordingly! It seems that your son is having a thyroid nodule, neurofibroma, cyst or a hemangioma-like lesion, if not a lymph node...! Wishing him good health; regards!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a78a002b-967d-44b2-b2d1-7aad285dabd1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109421</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>I m 12weeks pregnant with my second child. I h...</td>\n",
       "      <td>Hi there, thanks for the query. It looks like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a78a002b-967d-44b2-b2d1-7aad285dabd1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a78a002b-967d-44b2-b2d1-7aad285dabd1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a78a002b-967d-44b2-b2d1-7aad285dabd1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "109421  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                                    input  \\\n",
       "109421  I m 12weeks pregnant with my second child. I h...   \n",
       "\n",
       "                                                   output  \n",
       "109421  Hi there, thanks for the query. It looks like ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Doctor-HealthCare-100k.csv')\n",
    "df = df.sample(1000)\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nwjj5jgffGDj",
    "outputId": "1e5daf09-8e4a-4c14-8226-a7206b95f09d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 109421 to 96749\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  1000 non-null   object\n",
      " 1   input        1000 non-null   object\n",
      " 2   output       1000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "instruction_text = (\n",
    "    \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    ")\n",
    "\n",
    "df[\"instruction\"] = instruction_text\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151,
     "referenced_widgets": [
      "76dd987ccb4e4e91b316eff5fc77c75a",
      "14fefdefd8934ac08530d1aee41c1c85",
      "b90202cdfd00460f9c58767490947dff",
      "8b2a67b8bdef45c2bf0536ee28d79b25",
      "9b24b4dcb24f46f197c77fa4977b9c59",
      "559691e003564ce8beb6a8d37d9ad221",
      "8836ebd4f01b4a82a18d5f75f6271fa9",
      "b9b684a94e2948d98bbd1cb8ba7d5bbb",
      "fe49dcb5cc4342f8b37579fe393ae45f",
      "e80c17a9ef784f2ab8f0f5e7c194c0e7",
      "411dff643186468c8926e0468589c790"
     ]
    },
    "id": "gqYNMYzCeuPX",
    "outputId": "5a7b4a87-b0ec-4818-914e-4b98e3587c0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dd987ccb4e4e91b316eff5fc77c75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # КРИТИЧНО\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jcqe4ouymodi",
    "outputId": "3f892cf4-0d7a-49af-a3b5-8f4fc97f6a75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d137f34df6ff4f4da0905b79c63f67aa",
      "8c0d36a0475a4b8ea2c88bf01eb3ea1a",
      "c90ce16e0ef64407a5adf8b0e9e30751",
      "f04f647a7a5b480abb1fdcb0ea19a94a",
      "1501bef4bb8e403f9a4087c549e294e0",
      "8de6bbe8f9fc465cbfcec3ebfda61dd1",
      "fc1f180f665442808eec4e31187487cf",
      "5cbda54e9ec74d42b1bd8413a2cf3cc3",
      "f47ae2cee02a4bc7b9bf7e5f6e9a644c",
      "0fcfb0b47b2b46a8af59b316bc8d6674",
      "5565f531c9314fc68660c307d9a5e1d9"
     ]
    },
    "id": "Dn2a2ezVewV1",
    "outputId": "d0f0ad7e-059a-421d-d0c9-64aa9b804253"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d137f34df6ff4f4da0905b79c63f67aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def formatting_func(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": example[\"instruction\"]},\n",
    "        {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"output\"]},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    return {\"text\": text}\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(\n",
    "    formatting_func,\n",
    "    remove_columns=dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VA8D6pUe210",
    "outputId": "5a17b98c-e377-491b-cfc9-5f289247891e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 29,933,568 || all params: 3,115,872,256 || trainable%: 0.9607\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952,
     "referenced_widgets": [
      "ec234f914625411d9e0010f3c0e2f2aa",
      "a61ee71412e6469ea5baa3fe4ebf1620",
      "0c25a0ee12204080b12c65042aa5de45",
      "2b1648a381f940d9b2107d59b18deec4",
      "d191396cbe654b419f3d9533d84e6722",
      "c294a9dd44ab4325a7b4dde57f20b6f5",
      "390bbed14e5f4fdc8e34567b7fd6c275",
      "a0640eb7e445427ebcfb023a6b981cb9",
      "1ca6848594874c0ca04d5e56e8efab70",
      "1d952d66b38d429c9f326986a12cc6e6",
      "70bbfffe6b2b4624bdddd2523aeac5f7",
      "965003e9e7eb479585c57e25526315b0",
      "2e01b91706f04dcf80eec74767ffb22f",
      "24120d30ef2d46f8ba05c4ff935a32c7",
      "90d1895833794f9e8eaf481eb7a8e820",
      "708e664849a949d4a04fee201f7e4592",
      "ed30dfceead14dd092d455f6468d3424",
      "73ced3a0ae5c4fba978a05687360bf73",
      "f434f73e61f544a4ab0bab73823976f0",
      "1fe8b0ec96f34633a3a5739e59dcde04",
      "987f49f97d0141f39e1403bdc8a0b132",
      "37a0c49d191048e4a179e6e628be8c0c",
      "27cb53f22a0e4eda8a81cdde75424f51",
      "6858e4b4b1744cf5b959820a602f2a8c",
      "5c8cdff0cd654da7b8555a189efff56d",
      "22d3e108bd354ab4800f9b8a4cc0b0fd",
      "8be6e402978746c6a3f297d63561ee04",
      "d437f283413646c08a94b136f6016109",
      "9bf1965bd51a40e7b85e855819c76a75",
      "51fcba19798f4d18b83187aed13c57b1",
      "2404c9faa6b24095bb4de0d50efd4927",
      "73445a1aeac443ae96eecf92e54d51a7",
      "56d15a59a2434fb2a8b29a73313c6363"
     ]
    },
    "id": "VYVpcGsie2zQ",
    "outputId": "61237838-b8a4-434d-d1d2-6c2e476b6547"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec234f914625411d9e0010f3c0e2f2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965003e9e7eb479585c57e25526315b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cb53f22a0e4eda8a81cdde75424f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='249' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [249/250 16:54 < 00:04, 0.24 it/s, Epoch 0.99/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.401700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.264600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./ROW_Qwen3B_QLoRA\",\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    optim=\"adamw_torch\",        # ← безопасный оптимизатор\n",
    "    learning_rate=9e-5,         # Сделал чуть ниже среднего\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    fp16=False,                 # ← ВАЖНО\n",
    "    bf16=False,                 # ← ВАЖНО\n",
    "    max_grad_norm=0.0,          # ← КРИТИЧНО (иначе падение)\n",
    "\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length=1024,\n",
    "    packing=False,\n",
    "\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=sft_config,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# сохранить ТОЛЬКО обученный LoRA-адаптер\n",
    "model.eval()\n",
    "\n",
    "adapter_path = \"./ROW_Qwen3B_QLoRA/adapter\"\n",
    "model.save_pretrained(adapter_path)\n",
    "tokenizer.save_pretrained(adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xhlbJtpnM4y3",
    "outputId": "c5a160bf-1a99-44c6-9f8a-4db0ad48670e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a74a2c6b-9fbc-4f71-af84-2e31fedb47aa\", \"ROW_Qwen3B_QLoRA.tar.gz\", 140509184)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!tar -czf ROW_Qwen3B_QLoRA.tar.gz ROW_Qwen3B_QLoRA\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"ROW_Qwen3B_QLoRA.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ssfMXPtrnN1",
    "outputId": "cbbaa414-1225-4d27-c942-f56dce650fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Очистка памяти GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1136: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "/tmp/ipython-input-711827252.py:14: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_inductor/ops_handler.py:745: UserWarning: undefined OpHandler.data, please add missing op schema\n",
      "  warnings.warn(f\"undefined OpHandler.{name}, please add missing op schema\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Свободная память GPU: 7.13 GB занято, 10.26 GB зарезервировано\n",
      "Очистка завершена!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Полностью очищает память GPU без перезагрузки среды\"\"\"\n",
    "    print(\"Очистка памяти GPU...\")\n",
    "\n",
    "    # 1. Очистка кеша PyTorch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 2. Удаление переменных из памяти Python\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                # Удаляем тензоры\n",
    "                del obj\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 3. Принудительный сбор мусора\n",
    "    gc.collect()\n",
    "\n",
    "    # 4. Ещё раз очистка кеша CUDA\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 5. Освобождаем память от больших объектов\n",
    "    for i in range(2):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Свободная память GPU: {torch.cuda.memory_allocated()/1e9:.2f} GB занято, \"\n",
    "          f\"{torch.cuda.memory_reserved()/1e9:.2f} GB зарезервировано\")\n",
    "    print(\"Очистка завершена!\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cdAtuPpqI1w"
   },
   "source": [
    "# Инференс для сравнения BaseLine Модели и двух адаптеров QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2l-obUhkoHXW",
    "outputId": "e77fe770-a188-44fe-a810-2408057a151e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON initialized successfully: ./RAW_DATA_QLoRA.json\n",
      "Total QA entries: 30\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# DATA (30 QA)\n",
    "# ----------------------------\n",
    "queries = [\n",
    "    \"Hi! Please help,I have a small, slightly bumpy white splotch on the inside of both my cheeks. It is surrounded by small prominent purple veins. Is this cancerous? Im a 23 year old non-smoking male. Should I wait a few days or see a dr immediately? Thank you for your kindness.\",\n",
    "    \"my 1 month old son is showing signs of gas problem symptoms are -1) after feeding burping is not always proper gas will not come if we tap his back for 10-15 min 2) after some time he will show like he is swallowing some thing which has again come to his mouth from stomach, 3) some times milk will come threw his nose , 4)after sleeping 1/2 hour to 1 hour he will cry in sleep like he has some difficulty what i has to do can i try colicaid or grip water\",\n",
    "    \"Hi, may I answer your health queries right now ? Please type your query here...My 20 year old son is almost always tired and sleeps a LOT. This started 4-5 years ago and he had a very involved medical work-up at that time, but they did not come up with any cause or what to do about it. What could cause this? Is it worth trying a medical workup again?\",\n",
    "    \"hi Docter, I am 24 yrs old female staying in bangalore for the past 4 yrs. I am have Oily hair due to which i feel that I am facing hair loss as i have to shampoo my hair every alternate day. Can you please suggest me some measures to stop hair loss. Is it the water which is the problem??\",\n",
    "    \"My son has been diagnosed with 3mm vsd in echo, he was 6days then, paed cardiologist had put him on furosemide drops, the baby feeds very well, now he is 17days old, but continous urination since past few days bothering me very much since he i7 unable to achieve the desired weight, should i stop the furosemide drop,\",\n",
    "    \"Hi, my sister has a benign lipoma in her left wrist. She has had it since she was little and she s now 28. She has had surgery on it three times now, but doctors haven t been able to remove it because it s intertwined with nerves. Earlier today, it started to hurt more than usual and get really hot. She tried putting ice on it to cool it down, but it only helped a little and it quickly got hot again after the ice was taken off. Is this something we should be concerned about? Or is there something we can do for it?\",\n",
    "    \"I tested very high SGPT/SGOT levels. SGPT level is 122 and SGOT is 149.I have been advised to take Udiliv 300mg & mecobion-od twice daily. Would like to know if it is ok to have such medication and how serious may be my present condition and effect on my health. Is Any precaution I may need to take and any possible risks, as I am extremely tense about the situation. Many thanks in advance to advise.\",\n",
    "    \"I have a lump on the roof of my mouth ( the dentist had told me at one time, that I must have had it since I was a child) it is starting to bother me about a mouth ago. It feels like sand paper was rub on it and now all I feel is rawness, my sinuses are bothering me also, can this be connected? My ears feel stuffy and slightly burning and my throat feels like cotton is stuck in it. Please let me know what you think. I will also book an appointment with my Doctor.\",\n",
    "    \"Hello Im Joelmy girlfriend, after having 1 week period delay, took a pregnancy test, which resulted positive. However, 2 weeks later she blood-checked in a hospital and the resulted NOT pregnant. Though her period didnt come yet, I wasnt given any clear answer from the hospital, please help! thank you\",\n",
    "    \"I have been diagnosed with GAD since recovering from prostate cancer & possible duodenal cancer that was determined to be non malignant both within the past 2 years. I have tried 5 different SSRI s and 3 different SSNI s, none of which provided any relief. Side effects for most made my anxiety worse. I have also seen 4 psychiatrists with some minor success. CBT offering some help, the others, EMDR & Talk Therapy very little. The only relief I get is with 1MG Lorazepam as needed with no side effects. Why all the negativity re this medication.\",\n",
    "    \"i have been suffering right upper abdominal pain for the last 6 years.CT SCAN, ENDOSCOPY, ULTRASONOGRAHY,VARIOUS BLOOD TEST, AND HEPATO BILLIARY TEST FOUND NOTHING.NOW I AM FINDING A LITTLE HARD LIKE A PIPE THING JUST BELOW RIGT RIB CAGE. PLEASE SUGGEST.\",\n",
    "    \"i have developed belle palseythree days ago,i had shingles vaccination and flue vaccination done about two weeks ago Brain CT sacan and Mri normal,blood work normal,no diabetes,doctor say i have this condition due to schlnles live virus infection.i have no previous history of trauma. Is it okay to have one or two alcohol.\",\n",
    "    \"Hi my nephew is in thailand and has fractured his skull in two places resulting in atleast one bleed to his brain, he is on drugs to combat the bleeding, the doctor said he is willing to sign a form for him to fly 13 hrs home to uk, is this safe to do so?? thank you\",\n",
    "    \"recently told I had plaque thinning the arteries in my brain. can you give me good links that will tell me what this means, what caused it and how it can be fixed? I would like to know the good, bad and ugly.I have a multitude of medical conditions and would like to know if this is due to any of those conditions. thanks.\",\n",
    "    \"hi yesterday my dad had a fit - my mum described it like this\",\n",
    "    \"Hello I m a 23 year old female been having sharp chest pains. Started a few months ago I would get them randomly and then it would go away. Just last week it started but hasn t went away went the to the er last Friday and they said it was pleurisy never gave me any type of x ray or ct scan just diagnosed me n sent me home w a shot and prescription for naprosyn500mg. I have yet to get the medicine due to money issues at the moment but the pain hurts so bad when I breath and I just took 4 200mg ibprof. N still feel the pain\",\n",
    "    \"Hi, I m a woman in her late thirties. I am experiencing significant (obvious) swelling in my feet, ankles and calves almost every day. It goes away overnight (while I am asleep in bed) but seems to show up again every evening. I also experience puffiness in my face. I am overweight but not obese, and I walk at least 1.5 miles every day. My Grandmother has congestive heart failure (has had it a long time) and she began getting symptoms like this in her thirties. Do you think that is my future as well?\",\n",
    "    \"Hello Dr.I m 30 weeks pregnanthave detected with calculi of 3- 4 mm in both the kidneys.also pus cells with 150- 180/ hpf , protien, bacteria and yeast on 11.08.10on 12. 07.10 my urine report was pus cell with 25-30 hpf. Dr. gave me zocef (500) for five days after that pus cells reduced to 15-20 again Dr. gave me Taxim-o (200) for five days .but my pain didnt stopped im having severe pain in left side of the abdomen.and now after a month i just did my urine test my pus cell increased to 150-180 /hpf. Dr. suggested for Urine Culture test. but i will getmy report after days so till that report comes should i continue to take any antibiotic.please suggest me.Regardsmrs. shaikh\",\n",
    "    \"My 4 month old baby has a purple/reddish lump on her mid back that seems to be getting larger. Her doctor said it could be a platelet issue, I cant remember the term she used, and that we would watch it closely. Do you know what the doctor is talking about and should I get another opinion??\",\n",
    "    \"Hi! I am 5 wks. pregnant. I have a sluggish gallbladder, output of 27% , was to see a surgeon next week about having it removed until i found out i was pregnant. I am now having frequent loose stools. they almost appear oily or fatty.... greenish/brownish... not sure if its from the pregnancy or i guess my fear is that the gallbladder problem has created havoc on my pancreas and im freaking out\",\n",
    "    \"Hi, Im 29 yrs old and married for 6 yrs and not yet conceived at all. Had been in treatment from the 8th month of my marriage and took breaks too. GG, had been there for almost 2 yrs with laproscopy and 5 unsuccessful IUIs done. And 2 IUIs at Prashant multi speciality hospitals, which of first happened to be weakly positive. My problem is there is no diagnosis of what my problem is. My husbands count n motility is normal. My laprscopic n follicular studies give clear positive results. Inspite i have not conceived. Really wondering to know why we have to do IVF. I have a perfect 28 days cycle. My BMI is 29(overweight) and from novemeber 2010 have been identified thyroid too. Could there be anything like egg doesnt release? What to do if so? or egg release but too thick for the sperm to penetrate? what could be the reason? What to do now?\",\n",
    "    \"I have a tooth that was worked on 6 months ago.. they took my grey cavity out and filled it w a white one and also protected it w something.... they spent awhile on it. months later it was infected, so I took anti biotic... only bothered me a few times after minimal compared to b4 antibiotic... Now say 4 months I have a pimple like bubble on the side of my tooth... Is this conhhenry1978cerns to me suggestion I need a root canal??\",\n",
    "    \"Our 9 yr old boy has some issues with his running. His main issue is very tight hamstrings, along with weak hips. He wears orthotics and has been to PT as well as working with a running coach to help his bio mechanics. Things have improved apart from the hamstrings which have refused to loosen. Our PT mentioned mild Tethered Cord as an option, do you think this could be a possibility. He is a big guy, already 5ft and plays soccer, BB and tennis. Thanks Phil.\",\n",
    "    \"Hello. I am 24 years old. When I was in Second grade I got Hepatitis A. So I was between the age of 7-9. Is it still in my system after that many years? If I ever have children is there a possibility they will have it? Thanks for your time. Hope to hear from you soon.\",\n",
    "    \"Thank you; I tripped over a paving slab on 3rd May and fell forward flat on the ground, hitting my chin and my left knee particularly. The knee was never swollen but was very bruised. The leg was sore to walk on but gradually got better until last week when I had a difficult drive to work owing to heavy traffic. After that my knee became noticeably more sore (though not extreme pain) and since then it has got worse again. No muscular pain, swelling or bruising but it gets progressively painful if I try to walk and if I touch around (as opposed to upon) the kneecap it stings. I now can t really walk or drive and am off work. Apologies for the lengthy e-mail. I would appreciate your advice.\",\n",
    "    \"I have a feeling of a lump or something in my chest.squeezing across the mid section. plus trouble catching my breath sometimes,also a swishing noise in my chest to my head. after the squeezing and swishing I get a headache and my chest feels like I have been exercising. what is happing to me?\",\n",
    "    \"Hello I have a lump in the centre on the roof of my mouth. It has been there for almost 10 years. It becomes swollen, irritated and itchy for periods of time (days to weeks) and then settles down again, only to come back a week or so later. It feels like it is related to my allergies (eye conjunctivitis ). I did see an ENT specialist about 6 years ago. He told me it was just some dermatitis . What I really need is for someone to tell me how I can get some relief. It is very uncomfortable.\",\n",
    "    \"Hi, may I answer your health queries right now ? Please type your query here... I went to the doctor because of skipped heart beats, only lasting a second, which causes me to cough. Just didnt feel right. At the office my blood pressure was 169/92 which is 50 pts up for me, ekg turned out ok. He did chest xray and blood work. Waiting for results and appt. for echocardiogram. Heart feels like it beats a lot stronger.\",\n",
    "    \"Im 54 year old female, dont smoke, about 30 pounds overweight, my blood pressure typically is around, 128 over 80-something. About 18 months ago I had a chest pain that started in what felt like my stomach and spread across my chest, it was sharp and lasted a few minutes. I never had another until recently, now I get them a couple times a week. they feel like they start under my left breast and spread across both breasts and a feeling that I need to burp comes up into my throat, but I dont burp. Sometimes, it moves into my jaw. Once its gone, I feel fine. What do you think?\",\n",
    "    \"hellow... req u pls advise best gynecologist... five yrs has been passed we are unable to obtained one child.. in starting pregnancy was ok but after one Abortion we hv got serious prob. now we hv tried more even take consultancy with many gynecologist but unable to get pregnancy... pls help me and advise if Abortion is main reason not to getting pregnant ... ???\"\n",
    "]\n",
    "\n",
    "doctor_answers = [\n",
    "    \"Thanks for posting your query to Chat Doctor. After going through your history, I want to assure you not to get worried about it. White spots in oral cavity can occur due to many reasons which can only be told after proper visual examination. Do you have any other skin problem as sometimes these spots may be related to other systemic conditions? I would suggest you to visit a dentist and if needed a dermatologist for proper examination and treatment. Hope my answer will help you.\",\n",
    "    \"Hi... Thank you for consulting in Chat Doctor. This is called evening colic and is quite common in this age group. This happens when the baby sucks at the breast very fast and in eagerness to Chat Doctor. Unless the air comes out like burping or flatus this discomfort will be there. Usually I don't advice any medicines for this. The best ways are proper burping and prone position with gentle back patting.\",\n",
    "    \"I understand your concerns. From the description, diagnosis may not be possible. But your son could be suffering from depression which can cause lethargy and excessive sleep. I would suggest consulting a psychologist without delay.\",\n",
    "    \"It seems you are suffering from seborrheic dermatitis which can lead to hair fall. Use medicated shampoos, avoid excessive oiling, and take supplements like biotin. This should help.\",\n",
    "    \"Furosemide is a diuretic and increased urination is expected. You should not stop it without consulting your cardiologist. Regular follow-up is important.\",\n",
    "    \"This is most likely a ganglion rather than a lipoma. The pain and heat suggest infection. Consult an orthopedic surgeon; antibiotics and imaging like MRI may be needed.\",\n",
    "    \"Your liver enzymes are elevated, indicating liver disease. Udiliv is appropriate. Follow a low-fat diet and do not worry excessively. Levels should normalize.\",\n",
    "    \"Lumps on the roof of the mouth are often benign but need examination. Sinus and throat symptoms may or may not be related. Please see your doctor.\",\n",
    "    \"Blood beta-HCG is more accurate than urine tests. If blood test is negative, pregnancy is unlikely. Ultrasound can be done if doubt persists.\",\n",
    "    \"In resistant anxiety cases, alternative therapies like NLP or specialized acupuncture may help. Lorazepam can help symptoms but long-term strategy should be discussed.\",\n",
    "    \"HI. This may be a very small hernia in the center which is missed by all. Another possibility is costo-chon Chat Doctor. Hard-like-pipe thing is suggestive of this. Needs the investigations on this ground and a good clinical examination one can find these, if the Doctor is aware of such rare things. Can you post further information as to\",\n",
    "    \"Hi, Welcome to Chat Doctor .com I am Chat Doctor. Mariano Into Bruno Mascaras. I have gone through your query with diligence and would like you to know that I am here to help you. Alcohol affects nerve shaving alcohol will delay the healing process please avoid alcohol till you recover from bells palsy Hope you found the answer helpful. If you need any clarification / have doubts / have additional questions / have follow-up questions, then please do not hesitate in asking again. I will be happy to answer your questions. In the future, for continuity of care, I encourage you to contact me directly in Chat Doctor at http\",\n",
    "    \"Hi, Thank you for posting your query. I have noted your nephews symptoms and diagnosis. The fitness for flying depends on the severity of injury, CT scan findings and patients clinical condition. The fact that your nephew did not require surgery suggests that the injury is not severe. If his clinical condition is good, he would be fit to fly. It would be useful if you can upload a copy of his CT scan report here. I hope my answer helps. Please get back if you have any follow-up queries or if you require any additional information. Wishing you good health, Chat Doctor. Ly/\",\n",
    "    \"Hi, Thank you for posting your query. I think what you mean is atherosclerosis, where the arteries supplying blood to the brain get narrowed and may result in stroke due to ischemia (lack of blood flow). The treatment includes aspirin and stain use. The common risk factors for the same include high BP, sugar, cholesterol and smoking. Controlling these risk factors would stop the disease progression and prevent the strokes. Best wishes, Chat Doctor.\",\n",
    "    \"Hi, Based on details your father had R) focal onset seizure with secondary generalization and loss of consciousness. Need to rule out L) cerebral hemisphere structural lesion. Since he had previous history of Triple bypass surgery risk of ischemic stroke producing seizure is high. Hence, dose of anti platelets should be increased after ruling out brain bleed. He also requires anti-epileptic Chat Doctor. Consult nearby neurologist for further plan and management\",\n",
    "    \"Thanks for your question on Chat Doctor. In my opinion, you should rule out cardiac and pulmonary causes first for your intermittent chest pain. So get done ECG to rule out heart related causes. Get done chest x-ray to rule out pleurisy (inflammation of pleura) and lung related causes. If everything is normal then mostly you have anxiety and related chest discomfort. So better to consult psychiatrist and get done counselling sessions. Try to identify stressors in your life and start working on it. Avoid stress and anxiety. Be relax and calm.\",\n",
    "    \"Hello dear user! I have gone through your query and understood your concerns! Thank you for sharing them on Chat Doctor. We can't be sure that these symptoms you are experiencing now indicate heart failure without doing some examinations. Usually swollen ankles and feet are found in heart congestive failure, but in these cases, feet and ankles are more swollen in the evening and less in the morning. Kidney problems, diabetes, thyroid problems etc., may lead to similar symptoms. So to determine the real cause of these concerns I would recommend you to do some examinations to let us know more about your health.- Blood pressure monitoring-Blood sugar and lipids-Urine test, proteinuria- Liver enzymes, and kidney function indicators (creatinine, urea)- ECG-Heart ultrasound examination and cardiologist consultation doctor may ask for more examinations if he sees reasonable. After we get these results well be able to determine your condition and treat it accordingly. Feel free to ask us again on this website. I hope this answer was helpful to you! Please kindly rate it as helpful and write a short review about your experience with me! I would appreciate that a lot. Thank you and best regards! Chat Doctor.\",\n",
    "    \"Hi dear, I have gone through your question and understand your concerns. You are having recurrent urinary tract infection, which is most likely due to the calculi in the renal system. You should get active treatment for this infection, as it can cause preterm labor and delivery. You can continue taking plenty of fluids and oral antibiotics till the final culture report comes. Further management should be done accordingly. Hope you found the answer helpful. Wishing you good health. Regards Chat Doctor.\",\n",
    "    \"Hi, thanks for writing to Chat Doctor and sharing your babies health concerns with us! Well, If I were your treating Doctor for this case of the purple/reddish lump on the mid-back of baby, I would think of few possibilities\",\n",
    "    \"Hi and thank you so much for this query. I am so sorry to hear about what you are experiencing right now. A gall bladder problem can lead to diarrhea because food is not well digested as bile from the is very important in the digestion of fats. I will not particularly think that your pancreas has been damaged as you are not presenting with signs of pancreatitis which is often a pain. For now, stay relaxed and follow up with your doctors to figure out the exact cause and propose a treatment plan to you. I hope this ad Chat Doctor. Thank you so much for using our services, and please feel free to ask for clarifications if need be. I wish you the best of health.\",\n",
    "    \"Hi, I think you can go for few cycles of natural monitoring by ultrasound. You can track your follicles' growth by repeated ultrasound and when your follicles is more than 17 to 18 mm, take injection for rupturing the follicles. Be in contact with your husband every 2 to 3 days after your periods stop. Take progesterone for next 2 weeks. Do a urine pregnancy test at home after that. You can try like that for 3 cycles at least before going to IVF. Continue your thyroid medicine. Hope I have answered your question. Regards\",\n",
    "    \"Hi, Welcome to Chat Doctor forum, Your tooth which was filled earlier has got infection due to any residual caries or secondary caries. Due to caries, infection has reached the pulp and periapical abscess has formed. This pimple like bubble is due to abscess formed because pus needs a way to extrude itself. Consult a dentist for radio graphical examination done. Root canal treatment has to be done in this tooth. Take care\",\n",
    "    \"Hi, No. This doesn't seems like a case of tethered cord, as tethered cord has both motor and sensory signs and symptom and are usually progressive. This appears more like a case of cerebral palsy, tight hamstring with weak muscles is characteristic of hamstrings. Initial treatment is mainly through orthotics with adjuvant surgical procedures but to reach a diagnosis, a detailed physical examination is essential. As far as tight hamstrings is concerned, they can be lengthened by surgery. Take care. Hope I have answered your question. Let me know if I can assist you further.\",\n",
    "    \"Hi thanks for asking question. Let me clear your doubt dear... Hepatitis A spread in community by Eco oral route, means by contaminated food or water. So if you have this disease in childhood it is not spread to your child by you. Only if person take contaminated food or water by this virus then only hepatitis can occur. You have hepatitis A in childhood. So at that time protective antibody form in your system and protect you for many years. But virus cannot activate right now as it is already 10 years!! I hope I have solved your concern. Take care. Chat Doctor.\",\n",
    "    \"Brief Answer\",\n",
    "    \"Hi. I can understand your concern. Chest discomfort is commonly seen in bronchitis and lung infection. Since your chest x-ray is normal, no need to worry about lung infection. Possibility of bronchitis is more in your case. So better to consult pulmonologist and get done clinical examination of respiratory system and PFT (Pulmonary Function Test). PFT is needed for the diagnosis of bronchitis. It will also tell you about severity of the disease and treatment of bronchitis is based on severity only. You may need inhaled bronchodilators and inhaled corticosteroid (ICS)Don't worry, you will be alright. Hope I have solved your query. Wish you good health. Thanks.\",\n",
    "    \"Hi Evan, The problem you are describing can be associated with the allergy and with the sinus. If you are having some sort of sinusitis which is related with the nose sinuses infection or gallery, this can present as the problem which you are facing with. Allergic sinusitis is a chronic problem and is mostly because of some allergic substance and this can lead to a chronic condition. I would suggest you to consult some ENT surgeon regarding this problem and after proper history and examination and if required some investigation, it can be confirmed whether this is some sort of allergic problem or something different. Thanks.\",\n",
    "    \"Hello! Welcome and thank you for asking on Chat Doctor! I understand your concern and would explain that these skipped heart beats could be related to a cardiac arrhythmia. For this reason, I would recommend performing further tests\",\n",
    "    \"Hi There After going through your query I understand your concern. I would like to tell you that possibilities of acid Reflux/HERD more than a heart disease is there if you don't get breathless, palpitation with chest pain. It's advisable for you to avoid junk and spicy food to get relief and can use over the counter antacids also. Also get an ESG and Echocardiography done as a routine cardiac check up. Hopefully this will answer your query. Kind Regards Chat Doctor.\",\n",
    "    \"Hello and welcome to Chat Doctor, Abortion is not the cause of failure to conceive subsequently. Inability to conceive has many reasons.First, you have identified those days in your menstrual cycle when the chances of conception are maximum i.e. during ovulation. The period of ovulation can be determined by basal body temperature and changes in the cervical mucus. If conception does not take place even after taking care of the ovulation period, you need to get some investigations done. In your case, complete examination of the reproductive tract - ultrasonography and/ or hysterosalpingography, hormonal levels -estrogens, FSH and LH levels and follicular sac. In case of your husband, semen analysis should be under-taken. These are some of the investigations which will let your gynecologist know the cause of inability to conceive and thus plan management. Thanks and take care Chat Doctor.\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# CELL 0 — JSON INITIALIZATION (QUERIES + DOCTOR ANSWERS ONLY)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "JSON_PATH = \"./RAW_DATA_QLoRA.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD OR INIT JSON\n",
    "# ----------------------------\n",
    "if os.path.exists(JSON_PATH):\n",
    "    with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    results = {}\n",
    "\n",
    "# ----------------------------\n",
    "# VALID EMPTY MODEL TEMPLATE\n",
    "# ----------------------------\n",
    "EMPTY_MODEL_BLOCK = {\n",
    "    \"text\": None,\n",
    "    \"latency_sec\": None,\n",
    "    \"prompt_tokens\": None,\n",
    "    \"generated_tokens\": None,\n",
    "    \"total_tokens\": None,\n",
    "    \"timestamp_utc\": None\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# POPULATE JSON WITH DATA\n",
    "# ----------------------------\n",
    "for idx, (query, doctor_answer) in enumerate(zip(queries, doctor_answers), start=1):\n",
    "    key = str(idx)\n",
    "\n",
    "    if key not in results:\n",
    "        results[key] = {\n",
    "            \"query\": query,\n",
    "            \"doctor_answer\": doctor_answer,\n",
    "            \"base_model\": EMPTY_MODEL_BLOCK.copy(),\n",
    "            \"lora_model\": EMPTY_MODEL_BLOCK.copy(),\n",
    "            \"meta\": {\n",
    "                \"created_at_utc\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        # аккуратно дополняем, если структура частично существует\n",
    "        results[key].setdefault(\"query\", query)\n",
    "        results[key].setdefault(\"doctor_answer\", doctor_answer)\n",
    "        results[key].setdefault(\"base_model\", EMPTY_MODEL_BLOCK.copy())\n",
    "        results[key].setdefault(\"lora_model\", EMPTY_MODEL_BLOCK.copy())\n",
    "        results[key].setdefault(\n",
    "            \"meta\",\n",
    "            {\"created_at_utc\": datetime.now(timezone.utc).isoformat()}\n",
    "        )\n",
    "\n",
    "# ----------------------------\n",
    "# WRITE JSON\n",
    "# ----------------------------\n",
    "with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"JSON initialized successfully: {JSON_PATH}\")\n",
    "print(f\"Total QA entries: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "788ccf26ad5742a0a0d3b26ae35a73db",
      "02db63d29dc840faa832d7ce58ff9c70",
      "32e32546ca6f4aa2a9cad765dc602cea",
      "c0459769ad654bada6672a1c76556dbb",
      "d007513e27ac4c9391703d5e22f1b258",
      "88c6b5a5378b477dae765a8480e0f65c",
      "181a7c959b0d422e912f852e0f937e46",
      "986021900dd040da8bcdd9603c32f1b1",
      "cdc028f0b12746f289cc1c10143f1d85",
      "1a6b00c8efe440628ad54010386f2978",
      "948392e12dda4a46813735b642d05ad5",
      "e3b5cf340f58433eb9861e9351f83b43",
      "399497c0d3dd45c888298b05d1df9d07",
      "712c4dc401904fbda833db6d772896ff",
      "3678fd2557274c5e9b743dfd4bb27b30",
      "815e5c3280354b909237acc3681ba1f9",
      "e1510606783e436ab1768b2f34370248",
      "fa14c201f394406c9d0a56e771b07388",
      "d0faf50309624d33be0f433e007e1915",
      "7720f88dbc9e41aa9e96db2dee39bcf9",
      "30c3bb999ed44b82a836f0a0572a712f",
      "e3ac0dcc5a4c40f682c8cb936afb0492",
      "f6dcb267e3b04e6daa9ca77d34015c16",
      "a9a15cfb441e442388d556a679873cea",
      "847c5b3411bc445684067d8899e23a69",
      "b01c42879f22488d8f7420ad3f1e04ab",
      "479597584d7947e08464fde511789eb6",
      "af72b39ef0ee4a5a894e7e12797da56d",
      "01f04c4495a04181bb2c795bdd7bab65",
      "bf120e4816e047dda532c581bb94cacd",
      "94814808c0b14306907896d73f741d8d",
      "ece29b7728084ab3823589e72b2a4bee",
      "0b164a3c0acc4e94b3b5cdf907516976",
      "92e04d7a9f6c4301be0147b8318f7459",
      "7e6efaf2e1fb434386fdfc90bc28d62a",
      "ff748f8a9de244b18a936828ed36b896",
      "1e6a47de4666424f981acc5d02b347a4",
      "45185a9b48914310b38bfb221e6d3e79",
      "a1e2d59c365c41348eb802396c0c4d34",
      "674851f5f92e4acea8d22a7918440573",
      "6f7f73aa6c7b44ffba5a96f27d8c8591",
      "5446d7156f5a47318a11ef99dced35b0",
      "61bc8a6d082041e1a48eab39d9dceacf",
      "ee075640126c44e6b490ace9d15e65b7",
      "f47fe01ef4c74a0682d782ea4b5c9ef9",
      "865aff217183430ca45f245e7962f6ee",
      "3c1ddc74dfc9475da5534caa318e00b7",
      "a7e944d78a5d4414b60c0ce090fd443c",
      "eebcb62aa7e9464baea1a8fe05f2331c",
      "0733ee7f66af4d97906e329694489b5a",
      "00ec9e56743f49d4a2f1a65a7e9342ad",
      "799b66cecadb4a5b86f324ff4c2dd505",
      "2d18cfa5cf6e41c79ccf6292e63a73b2",
      "817cf2d7cb3f44b4bc917c575c5efc3a",
      "3a35fe2c42824b23b5e7b75437fff369",
      "e6e3cc2820ea4e7f8e588a58c66a3000",
      "f803ed29672545809f97a61aa08a88a1",
      "b2a6efcf05ab47b7b6de6ffc200b9fcf",
      "6f5fd20bb8d544a0bc74b76849acfa51",
      "c7c526d2a6d34ca597f45ea11813699e",
      "bed17a8e6b264424b86cf61d545c3665",
      "4bbc6ea51c1840d0b186220529a3f1ca",
      "b8f9e7969efb492da107e695f147d2de",
      "5b83a2f358674222a568858415f87988",
      "2b921d5feb2a4980bcab650f20ab8409",
      "55fae0c1101046afbb334b7a7ba5b26e",
      "c3e7b015045e40c7bde75e1d74f3d255",
      "690c1f593b554704b17e932c1a067c90",
      "318b2f2e2ca64f8085935849673b0d8d",
      "81dde203920b4ce29c4ae8c84450359b",
      "79795f1adc6d45f1bf594cff406bdf76",
      "894278a2455a4278a7c5f2a2ac053f7b",
      "a8cecbc7902f4da6ad6ea1d6237ea289",
      "844785c474a142b2bde1bf810a718363",
      "0970428e60204df49c1e61fdc7a785ec",
      "04a2808258864502ae6b111eec600617",
      "794246aaf9234c248c229c5deea71be7",
      "df9f2210e28c47beafc0b705722547cc",
      "4711e67c8c694910bf946201c1d118e3",
      "d117d0b5992f4433b6ef5e41aedc3c2a",
      "7a5ff420a3144a699481ae439c659074",
      "73314bea49304514b59ab23fec6e6735",
      "1ddfd14170d2496f8e5c36ec2b2be16f",
      "5d1820ca22fe4ae6b314a9ce976cabe9",
      "baaf023e556948e18ff1d9bc47b475ab",
      "ca0614c14dad402298d41b06b020bb01",
      "5d2d08198e9a4baca8e5967deb96adb9",
      "e202e4e9acc441f895b05f8d546358c5",
      "5982b0060bb04f84a5d02cdbf0ba40d2",
      "44456b6ba8af446ba613ecb71287a612",
      "49d2e87db3ca4e59a8aa422acf9df002",
      "3717373cb4cc434ea317c223cd9e8ff8",
      "c47ce0a7c57a475292304e2ac93286b2",
      "8be5f8253e614f508dbaf8a3da164503",
      "5076ca2173e94ba8b029089d46511ecd",
      "d70e08d9c0624be4acac1ecff14d2b28",
      "c05c4300dbba4b558671de7712d32929",
      "750b37d230f64f0987f48de6fbc38a30",
      "5b9a9c9358794aafb854fac11e934ac8",
      "5b0553eb1fd44845a26c5eae9f39eb8a",
      "ff05e71a42834b5c97695639b2e7a45d",
      "d8bda09683334807b3ca7e64bde08576",
      "07a84224075e4275917fa040ede74d27",
      "2f44eb39bd0741178210d577160988d6",
      "fd1f6b027b7149cd85b68db842956d1e",
      "186384ca44494680aa63aecfe2f51209",
      "9e273c3180504d549d52bfa72ab8ee7f",
      "689ef49cb9e04001ac19e9930cb6959a",
      "b9c2935d4fa244cf820ffb12e4461742",
      "994784b6477f45208db14b92224a472a",
      "776c789cbcd0489fb71f3979983790a8",
      "2e86f68c4ac1481c9ecb8a047822e96f",
      "c7301344527c46039d1abcc4ea52e474",
      "cd51661b65544d39a28b6cc111613552",
      "0a9e4840c88d4b55ae6697d24dd96f58",
      "fc6cb9a8c3d04a7b83c326b4bae674aa",
      "6cc37ed782644e48a339663cc00e6dac",
      "59c57bd5067f47788f177e5bc72d802d",
      "f6a281cda76e459aacb827ecb3ea15b1",
      "75eeb57b641f440f93a09becea65dac6",
      "569d2a22932a4c1b91ab0b73f7768a59"
     ]
    },
    "id": "6hXeueHDnEPB",
    "outputId": "21323298-ba0d-4f05-b9f1-c17aee0f58b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788ccf26ad5742a0a0d3b26ae35a73db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b5cf340f58433eb9861e9351f83b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dcb267e3b04e6daa9ca77d34015c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e04d7a9f6c4301be0147b8318f7459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BASE model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47fe01ef4c74a0682d782ea4b5c9ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e3cc2820ea4e7f8e588a58c66a3000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e7b015045e40c7bde75e1d74f3d255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9f2210e28c47beafc0b705722547cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5982b0060bb04f84a5d02cdbf0ba40d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0553eb1fd44845a26c5eae9f39eb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776c789cbcd0489fb71f3979983790a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BASE] QA #1\n",
      "[BASE] QA #2\n",
      "[BASE] QA #3\n",
      "[BASE] QA #4\n",
      "[BASE] QA #5\n",
      "[BASE] QA #6\n",
      "[BASE] QA #7\n",
      "[BASE] QA #8\n",
      "[BASE] QA #9\n",
      "[BASE] QA #10\n",
      "[BASE] QA #11\n",
      "[BASE] QA #12\n",
      "[BASE] QA #13\n",
      "[BASE] QA #14\n",
      "[BASE] QA #15\n",
      "[BASE] QA #16\n",
      "[BASE] QA #17\n",
      "[BASE] QA #18\n",
      "[BASE] QA #19\n",
      "[BASE] QA #20\n",
      "[BASE] QA #21\n",
      "[BASE] QA #22\n",
      "[BASE] QA #23\n",
      "[BASE] QA #24\n",
      "[BASE] QA #25\n",
      "[BASE] QA #26\n",
      "[BASE] QA #27\n",
      "[BASE] QA #28\n",
      "[BASE] QA #29\n",
      "[BASE] QA #30\n",
      "BASE inference completed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1 — BASE MODEL INFERENCE (EXISTING JSON)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "JSON_PATH = \"./QLoRA.json\"\n",
    "\n",
    "DTYPE = torch.float16\n",
    "\n",
    "# ----------------------------\n",
    "# QUANTIZATION\n",
    "# ----------------------------\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=DTYPE,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# TOKENIZER\n",
    "# ----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# INFERENCE FUNCTION\n",
    "# ----------------------------\n",
    "def run_inference(model, query: str) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id)\n",
    "    prompt_tokens = inputs.shape[1]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    latency = time.perf_counter() - start_time\n",
    "\n",
    "    generated_tokens = outputs.shape[1] - prompt_tokens\n",
    "    total_tokens = outputs.shape[1]\n",
    "\n",
    "    generated = outputs[:, prompt_tokens:]\n",
    "    text = tokenizer.decode(generated[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"latency_sec\": round(latency, 4),\n",
    "        \"prompt_tokens\": int(prompt_tokens),\n",
    "        \"generated_tokens\": int(generated_tokens),\n",
    "        \"total_tokens\": int(total_tokens),\n",
    "        \"timestamp_utc\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD BASE MODEL\n",
    "# ----------------------------\n",
    "print(\"Loading BASE model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "base_model.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD JSON\n",
    "# ----------------------------\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# BASE INFERENCE LOOP\n",
    "# ----------------------------\n",
    "for key in sorted(results.keys(), key=lambda x: int(x)):\n",
    "    entry = results[key]\n",
    "\n",
    "    # уже есть результат → пропускаем\n",
    "    if entry.get(\"base_model\", {}).get(\"text\") is not None:\n",
    "        continue\n",
    "\n",
    "    print(f\"[BASE] QA #{key}\")\n",
    "\n",
    "    base_out = run_inference(base_model, entry[\"query\"])\n",
    "    entry[\"base_model\"] = base_out\n",
    "\n",
    "    with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"BASE inference completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593,
     "referenced_widgets": [
      "3f0e6a0e95e64667935461b865cf15ea",
      "c0ec606ca2e94283a17926ab91e8f173",
      "7f5b055fc28a49a88c89def4826ee682",
      "6ef151bba0c64adcbd5ea01a4e3249a6",
      "e12c2d9d6e5840f4ab817a1f8b669d2c",
      "c033ddf19be24094aba631c62aad4ced",
      "c0e33acf5e9740218a8a04241f4e1a17",
      "6fa85f0980eb4fc29eee2500521c8f86",
      "eb96d7efcf6041a6b74cfec22760916d",
      "6a4aa0d5268942519fb63dc8d781ff73",
      "c771674dc7244908a32c23c709672652"
     ]
    },
    "id": "z1UUQpLbnToP",
    "outputId": "52564a34-58d3-4bcd-f87d-a0f58db0cf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0e6a0e95e64667935461b865cf15ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA] QA #1\n",
      "[LoRA] QA #2\n",
      "[LoRA] QA #3\n",
      "[LoRA] QA #4\n",
      "[LoRA] QA #5\n",
      "[LoRA] QA #6\n",
      "[LoRA] QA #7\n",
      "[LoRA] QA #8\n",
      "[LoRA] QA #9\n",
      "[LoRA] QA #10\n",
      "[LoRA] QA #11\n",
      "[LoRA] QA #12\n",
      "[LoRA] QA #13\n",
      "[LoRA] QA #14\n",
      "[LoRA] QA #15\n",
      "[LoRA] QA #16\n",
      "[LoRA] QA #17\n",
      "[LoRA] QA #18\n",
      "[LoRA] QA #19\n",
      "[LoRA] QA #20\n",
      "[LoRA] QA #21\n",
      "[LoRA] QA #22\n",
      "[LoRA] QA #23\n",
      "[LoRA] QA #24\n",
      "[LoRA] QA #25\n",
      "[LoRA] QA #26\n",
      "[LoRA] QA #27\n",
      "[LoRA] QA #28\n",
      "[LoRA] QA #29\n",
      "[LoRA] QA #30\n",
      "LoRA inference completed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2 — LoRA MODEL INFERENCE (EXISTING JSON)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "ADAPTER_PATH = \"./RAW_Qwen3B_QLoRA/adapter\"\n",
    "JSON_PATH = \"./RAW_DATA_QLoRA.json\"\n",
    "\n",
    "DTYPE = torch.float16\n",
    "\n",
    "# ----------------------------\n",
    "# QUANTIZATION\n",
    "# ----------------------------\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=DTYPE,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# TOKENIZER\n",
    "# ----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# INFERENCE FUNCTION\n",
    "# ----------------------------\n",
    "def run_inference(model, query: str) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id)\n",
    "    prompt_tokens = inputs.shape[1]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    latency = time.perf_counter() - start_time\n",
    "\n",
    "    generated_tokens = outputs.shape[1] - prompt_tokens\n",
    "    total_tokens = outputs.shape[1]\n",
    "\n",
    "    generated = outputs[:, prompt_tokens:]\n",
    "    text = tokenizer.decode(generated[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"latency_sec\": round(latency, 4),\n",
    "        \"prompt_tokens\": int(prompt_tokens),\n",
    "        \"generated_tokens\": int(generated_tokens),\n",
    "        \"total_tokens\": int(total_tokens),\n",
    "        \"timestamp_utc\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD LoRA MODEL\n",
    "# ----------------------------\n",
    "print(\"Loading LoRA model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    ADAPTER_PATH,\n",
    ")\n",
    "lora_model.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD JSON\n",
    "# ----------------------------\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# LoRA INFERENCE LOOP\n",
    "# ----------------------------\n",
    "for key in sorted(results.keys(), key=lambda x: int(x)):\n",
    "    entry = results[key]\n",
    "\n",
    "    if entry.get(\"lora_model\", {}).get(\"text\") is not None:\n",
    "        continue\n",
    "\n",
    "    print(f\"[LoRA] QA #{key}\")\n",
    "\n",
    "    lora_out = run_inference(lora_model, entry[\"query\"])\n",
    "    entry[\"lora_model\"] = lora_out\n",
    "\n",
    "    with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"LoRA inference completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "af23c275e7d34738acdf7a488ed90f27",
      "450fd0ac1f6e41e88a78e1b5e821d3df",
      "feff59b1de19477880756407bab7f5a0",
      "4d8ff0e32b5545949e1bd0de2cc87955",
      "d35de935108f474d9bf7c907e062a88a",
      "a3041368e0aa4231b649d9093a409d38",
      "6635d3d54eb5423eaefd367abcbd39c1",
      "771b205903274077b01c263cfff94c13",
      "b0e543c0a8a749378372f0a6c4178f61",
      "e34dd7f123ca4316802c614af488ddae",
      "21a44dc42cec4c899c0bee916d60d1fe",
      "18f76d34797a44c2bbefcf111d5b6036",
      "6e5e51ffa619424292302fb5f9a2d9f1",
      "d8f2081db03643b1bd3d32d3065e7ff8",
      "6d456cf374764a6ebcaaf33ddb6e3b40",
      "a5c9bd60ca5543f99694da829a9ba443",
      "ffc366df253c4137b3c6a59740c2e3f3",
      "8b5a4dae28064ff7a67b8de9cf48f5c9",
      "edb20fe3641b4cc18ad2e58d1b5adbc4",
      "7843e609cdc746e19b591ee751eba8cf",
      "586a3dc493904c9aa2768494981de5a0",
      "579c6b6bfafe4e47826de8f5329db72a"
     ]
    },
    "id": "KHCyPgL6JAku",
    "outputId": "85b3d1a1-516b-473a-d785-9331a94863b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BASE model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af23c275e7d34738acdf7a488ed90f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading LoRA model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f76d34797a44c2bbefcf111d5b6036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест адаптера, обученного на исходных данных\n",
      "\n",
      "========================================\n",
      "QA #1\n",
      "========================================\n",
      "\n",
      "ЗАПРОС ПОЛЬЗОВАТЕЛЯ:\n",
      "Hi! Please help,I have a small, slightly bumpy white splotch on the inside of both my cheeks. It is surrounded by small prominent purple veins. Is this cancerous? Im a 23 year old non-smoking male. Should I wait a few days or see a dr immediately? Thank you for your kindness.\n",
      "\n",
      "ЭТАЛОННЫЙ ОТВЕТ ВРАЧА:\n",
      "Thanks for posting your query to Chat Doctor. After going through your history, I want to assure you not to get worried about it. White spots in oral cavity can occur due to many reasons which can only be told after proper visual examination. Do you have any other skin problem as sometimes these spots may be related to other systemic conditions? I would suggest you to visit a dentist and if needed a dermatologist for proper examination and treatment. Hope my answer will help you.\n",
      "\n",
      "ОТВЕТ БАЗОВОЙ МОДЕЛИ:\n",
      "It's important to approach any concerning skin changes with caution, but it's also crucial not to overreact. The symptoms you described—small, slightly bumpy white splotches with prominent purple veins—could be indicative of several conditions, including benign growths like keratoses or potentially more concerning conditions such as oral leukoplakia or even early signs of malignancy.\n",
      "\n",
      "Given that you are a 23-year-old non-smoking male, the risk of certain cancers (such as oral cancer) is relatively low. However, self-diagnosis can be challenging, especially when dealing with potentially serious conditions. Given your age and the nature of the lesion, it would be prudent to seek medical evaluation sooner rather than later.\n",
      "\n",
      "I recommend scheduling an appointment with a healthcare provider, preferably a dentist or an oral surgeon, who can examine the lesion in person. They may perform a biopsy if they suspect it could be something other than a benign condition. Early diagnosis and treatment are key, so do not delay seeking professional advice.\n",
      "\n",
      "In the meantime, avoid picking at or irritating the area, and maintain good oral hygiene practices. Your primary care physician or a specialist can provide guidance based on their examination.\n",
      "\n",
      "ОТВЕТ МОДЕЛИ С АДАПТЕРОМ:\n",
      "Hello, Welcome to Chat Doctor, As you have a white patch on the cheek which is surrounded by small prominent purple veins. This could be due to a condition called as oral candidiasis. It is a fungal infection of the mouth. The fungus grows in moist areas of the mouth. It is commonly seen in people who wear dentures, people with diabetes, people who take broad spectrum antibiotics, people who smoke, people who drink alcohol, people who have HIV/AIDS, people who have had radiation therapy to the head and neck area. You need to consult an oral physician for proper diagnosis and treatment. You can take antifungal medications like fluconazole, itraconazole, etc. Take care.\n",
      "\n",
      "========================================\n",
      "QA #2\n",
      "========================================\n",
      "\n",
      "ЗАПРОС ПОЛЬЗОВАТЕЛЯ:\n",
      "my 1 month old son is showing signs of gas problem symptoms are -1) after feeding burping is not always proper gas will not come if we tap his back for 10-15 min 2) after some time he will show like he is swallowing some thing which has again come to his mouth from stomach, 3) some times milk will come threw his nose , 4)after sleeping 1/2 hour to 1 hour he will cry in sleep like he has some difficulty what i has to do can i try colicaid or grip water\n",
      "\n",
      "ЭТАЛОННЫЙ ОТВЕТ ВРАЧА:\n",
      "Hi... Thank you for consulting in Chat Doctor. This is called evening colic and is quite common in this age group. This happens when the baby sucks at the breast very fast and in eagerness to Chat Doctor. Unless the air comes out like burping or flatus this discomfort will be there. Usually I don't advice any medicines for this. The best ways are proper burping and prone position with gentle back patting.\n",
      "\n",
      "ОТВЕТ БАЗОВОЙ МОДЕЛИ:\n",
      "It sounds like your baby may be experiencing some discomfort related to gastroesophageal reflux (GER) and possibly gas. Here are some steps you can take:\n",
      "\n",
      "1. **Burping**: Ensure that your baby is burped after each feeding. Sometimes, a gentle pat on the back can help release trapped air.\n",
      "\n",
      "2. **Positioning**: After feeding, hold your baby upright for about 20-30 minutes to allow gravity to help with digestion. This can also help reduce the likelihood of milk coming out through the nose.\n",
      "\n",
      "3. **Gravity Positioning**: When you lay your baby down for a nap, keep them in a slightly inclined position. You can use a rolled towel under their head to achieve this. This can help prevent stomach contents from flowing back into the esophagus.\n",
      "\n",
      "4. **Colic Relief Drops**: Colic drops such as Simethicone (e.g., Colic Aid) can sometimes help with gas and discomfort. Follow the instructions on the package or consult with your pediatrician for the appropriate dosage.\n",
      "\n",
      "5. **Gripe Water**: Gripe Water is a natural remedy that some parents find helpful. It contains ingredients like fennel, ginger, and chamomile, which are believed to soothe the baby's digestive system. Again, follow the instructions carefully.\n",
      "\n",
      "6. **Consult Your Pediatrician**: If these measures do not provide relief, it would be wise to consult your pediatrician. They can assess your baby and rule out other potential causes of the symptoms. Persistent crying at night could indicate more serious issues that need attention.\n",
      "\n",
      "Remember, every baby is different, and what works for one might not work for another. Always seek professional advice when in doubt.\n",
      "\n",
      "ОТВЕТ МОДЕЛИ С АДАПТЕРОМ:\n",
      "Hi, Welcome to Chat Doctor. I have gone through your query and understand your concern. Your baby seems to be having gastroesophageal reflux disease (GERD). It is common in infants. The symptoms you have mentioned are typical of GERD. You should give him antacids like pantoprazole and antihistamines like cetirizine. Also, you should give him probiotics like lactobacillus. If the symptoms persist, you should consult a pediatrician. Hope this helps. Best regards.\n",
      "\n",
      "========================================\n",
      "QA #3\n",
      "========================================\n",
      "\n",
      "ЗАПРОС ПОЛЬЗОВАТЕЛЯ:\n",
      "Hi, may I answer your health queries right now ? Please type your query here...My 20 year old son is almost always tired and sleeps a LOT. This started 4-5 years ago and he had a very involved medical work-up at that time, but they did not come up with any cause or what to do about it. What could cause this? Is it worth trying a medical workup again?\n",
      "\n",
      "ЭТАЛОННЫЙ ОТВЕТ ВРАЧА:\n",
      "I understand your concerns. From the description, diagnosis may not be possible. But your son could be suffering from depression which can cause lethargy and excessive sleep. I would suggest consulting a psychologist without delay.\n",
      "\n",
      "ОТВЕТ БАЗОВОЙ МОДЕЛИ:\n",
      "It's understandable to be concerned about your son's persistent fatigue and sleepiness. While the initial workup didn't identify a specific cause, there are several potential underlying conditions that could explain these symptoms. Some possibilities include chronic fatigue syndrome, depression, thyroid disorders, sleep disorders (such as sleep apnea), or even certain autoimmune diseases.\n",
      "\n",
      "Given that these symptoms have persisted for several years, it might indeed be worthwhile to revisit the medical workup. This could include additional tests such as thyroid function tests, sleep studies, and possibly more detailed blood work or imaging studies. Consulting with specialists, such as a sleep specialist or an endocrinologist, might also provide new insights.\n",
      "\n",
      "Encouraging your son to maintain open communication with his healthcare provider and keeping a detailed sleep diary can also be beneficial. It's important to rule out any reversible causes before considering more complex or long-term treatments.\n",
      "\n",
      "If you decide to proceed with another comprehensive evaluation, make sure to document all previous test results and consult with a primary care physician or a specialist who can coordinate the new evaluations and treatments.\n",
      "\n",
      "ОТВЕТ МОДЕЛИ С АДАПТЕРОМ:\n",
      "Hello, I have gone through your question. I can understand your concern. He has been evaluated by a physician. No specific cause was found. So you need to repeat the evaluation. He should be evaluated for thyroid function test, vitamin D level, iron studies, complete blood count, ESR, CRP, serum ferritin, serum protein electrophoresis, serum lactate dehydrogenase, serum alkaline phosphatase, serum creatinine, serum urea, serum electrolytes, serum calcium, serum magnesium, serum phosphorus, serum parathyroid hormone, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxyvitamin D, serum 1,25-dihydroxyvitamin D, serum 24-hydroxyvitamin D, serum 25-hydroxy\n",
      "\n",
      "========================================\n",
      "QA #4\n",
      "========================================\n",
      "\n",
      "ЗАПРОС ПОЛЬЗОВАТЕЛЯ:\n",
      "hi Docter, I am 24 yrs old female staying in bangalore for the past 4 yrs. I am have Oily hair due to which i feel that I am facing hair loss as i have to shampoo my hair every alternate day. Can you please suggest me some measures to stop hair loss. Is it the water which is the problem??\n",
      "\n",
      "ЭТАЛОННЫЙ ОТВЕТ ВРАЧА:\n",
      "It seems you are suffering from seborrheic dermatitis which can lead to hair fall. Use medicated shampoos, avoid excessive oiling, and take supplements like biotin. This should help.\n",
      "\n",
      "ОТВЕТ БАЗОВОЙ МОДЕЛИ:\n",
      "Hello! It's important to note that hair loss can be influenced by various factors, including genetics, hormones, diet, stress levels, and more. Oily hair can sometimes contribute to hair loss, but it's not typically the primary cause.\n",
      "\n",
      "Here are some steps you might consider:\n",
      "\n",
      "1. **Hair Care Routine**: Ensure your hair care routine is gentle. Use mild shampoos and avoid harsh chemicals. Opt for products that are specifically formulated for oily hair.\n",
      "\n",
      "2. **Shampoo Frequency**: Shampooing every other day might be too frequent. Try reducing this to once or twice a week, depending on how oily your hair is.\n",
      "\n",
      "3. **Detangling Gently**: When detangling, use a wide-tooth comb to minimize pulling and tugging on the hair.\n",
      "\n",
      "4. **Moisturize**: Apply a leave-in conditioner or oil (like coconut oil) to your hair after washing to help manage oil production and add moisture.\n",
      "\n",
      "5. **Healthy Diet**: Eating a balanced diet rich in vitamins and minerals can support overall hair health. Foods like eggs, nuts, seeds, leafy greens, and fruits are beneficial.\n",
      "\n",
      "6. **Stress Management**: High stress levels can contribute to hair loss. Consider incorporating relaxation techniques such as yoga, meditation, or hobbies into your daily routine.\n",
      "\n",
      "7. **Consult a Professional**: If you're concerned about hair loss, consulting with a dermatologist or trichologist can provide personalized advice and treatment options.\n",
      "\n",
      "Remember, hair loss can also be related to underlying medical conditions, so if you're still concerned, it's best to seek professional medical advice.\n",
      "\n",
      "ОТВЕТ МОДЕЛИ С АДАПТЕРОМ:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "adapter_path = \"./ROW_Qwen3B_QLoRA/adapter\"\n",
    "\n",
    "# ----------------------------\n",
    "# DATA (30 QA)\n",
    "# ----------------------------\n",
    "queries = [\n",
    "    \"Hi! Please help,I have a small, slightly bumpy white splotch on the inside of both my cheeks. It is surrounded by small prominent purple veins. Is this cancerous? Im a 23 year old non-smoking male. Should I wait a few days or see a dr immediately? Thank you for your kindness.\",\n",
    "    \"my 1 month old son is showing signs of gas problem symptoms are -1) after feeding burping is not always proper gas will not come if we tap his back for 10-15 min 2) after some time he will show like he is swallowing some thing which has again come to his mouth from stomach, 3) some times milk will come threw his nose , 4)after sleeping 1/2 hour to 1 hour he will cry in sleep like he has some difficulty what i has to do can i try colicaid or grip water\",\n",
    "    \"Hi, may I answer your health queries right now ? Please type your query here...My 20 year old son is almost always tired and sleeps a LOT. This started 4-5 years ago and he had a very involved medical work-up at that time, but they did not come up with any cause or what to do about it. What could cause this? Is it worth trying a medical workup again?\",\n",
    "    \"hi Docter, I am 24 yrs old female staying in bangalore for the past 4 yrs. I am have Oily hair due to which i feel that I am facing hair loss as i have to shampoo my hair every alternate day. Can you please suggest me some measures to stop hair loss. Is it the water which is the problem??\",\n",
    "    \"My son has been diagnosed with 3mm vsd in echo, he was 6days then, paed cardiologist had put him on furosemide drops, the baby feeds very well, now he is 17days old, but continous urination since past few days bothering me very much since he i7 unable to achieve the desired weight, should i stop the furosemide drop,\",\n",
    "    \"Hi, my sister has a benign lipoma in her left wrist. She has had it since she was little and she s now 28. She has had surgery on it three times now, but doctors haven t been able to remove it because it s intertwined with nerves. Earlier today, it started to hurt more than usual and get really hot. She tried putting ice on it to cool it down, but it only helped a little and it quickly got hot again after the ice was taken off. Is this something we should be concerned about? Or is there something we can do for it?\",\n",
    "    \"I tested very high SGPT/SGOT levels. SGPT level is 122 and SGOT is 149.I have been advised to take Udiliv 300mg & mecobion-od twice daily. Would like to know if it is ok to have such medication and how serious may be my present condition and effect on my health. Is Any precaution I may need to take and any possible risks, as I am extremely tense about the situation. Many thanks in advance to advise.\",\n",
    "    \"I have a lump on the roof of my mouth ( the dentist had told me at one time, that I must have had it since I was a child) it is starting to bother me about a mouth ago. It feels like sand paper was rub on it and now all I feel is rawness, my sinuses are bothering me also, can this be connected? My ears feel stuffy and slightly burning and my throat feels like cotton is stuck in it. Please let me know what you think. I will also book an appointment with my Doctor.\",\n",
    "    \"Hello Im Joelmy girlfriend, after having 1 week period delay, took a pregnancy test, which resulted positive. However, 2 weeks later she blood-checked in a hospital and the resulted NOT pregnant. Though her period didnt come yet, I wasnt given any clear answer from the hospital, please help! thank you\",\n",
    "    \"I have been diagnosed with GAD since recovering from prostate cancer & possible duodenal cancer that was determined to be non malignant both within the past 2 years. I have tried 5 different SSRI s and 3 different SSNI s, none of which provided any relief. Side effects for most made my anxiety worse. I have also seen 4 psychiatrists with some minor success. CBT offering some help, the others, EMDR & Talk Therapy very little. The only relief I get is with 1MG Lorazepam as needed with no side effects. Why all the negativity re this medication.\",\n",
    "    \"i have been suffering right upper abdominal pain for the last 6 years.CT SCAN, ENDOSCOPY, ULTRASONOGRAHY,VARIOUS BLOOD TEST, AND HEPATO BILLIARY TEST FOUND NOTHING.NOW I AM FINDING A LITTLE HARD LIKE A PIPE THING JUST BELOW RIGT RIB CAGE. PLEASE SUGGEST.\",\n",
    "    \"i have developed belle palseythree days ago,i had shingles vaccination and flue vaccination done about two weeks ago Brain CT sacan and Mri normal,blood work normal,no diabetes,doctor say i have this condition due to schlnles live virus infection.i have no previous history of trauma. Is it okay to have one or two alcohol.\",\n",
    "    \"Hi my nephew is in thailand and has fractured his skull in two places resulting in atleast one bleed to his brain, he is on drugs to combat the bleeding, the doctor said he is willing to sign a form for him to fly 13 hrs home to uk, is this safe to do so?? thank you\",\n",
    "    \"recently told I had plaque thinning the arteries in my brain. can you give me good links that will tell me what this means, what caused it and how it can be fixed? I would like to know the good, bad and ugly.I have a multitude of medical conditions and would like to know if this is due to any of those conditions. thanks.\",\n",
    "    \"hi yesterday my dad had a fit - my mum described it like this\",\n",
    "    \"Hello I m a 23 year old female been having sharp chest pains. Started a few months ago I would get them randomly and then it would go away. Just last week it started but hasn t went away went the to the er last Friday and they said it was pleurisy never gave me any type of x ray or ct scan just diagnosed me n sent me home w a shot and prescription for naprosyn500mg. I have yet to get the medicine due to money issues at the moment but the pain hurts so bad when I breath and I just took 4 200mg ibprof. N still feel the pain\",\n",
    "    \"Hi, I m a woman in her late thirties. I am experiencing significant (obvious) swelling in my feet, ankles and calves almost every day. It goes away overnight (while I am asleep in bed) but seems to show up again every evening. I also experience puffiness in my face. I am overweight but not obese, and I walk at least 1.5 miles every day. My Grandmother has congestive heart failure (has had it a long time) and she began getting symptoms like this in her thirties. Do you think that is my future as well?\",\n",
    "    \"Hello Dr.I m 30 weeks pregnanthave detected with calculi of 3- 4 mm in both the kidneys.also pus cells with 150- 180/ hpf , protien, bacteria and yeast on 11.08.10on 12. 07.10 my urine report was pus cell with 25-30 hpf. Dr. gave me zocef (500) for five days after that pus cells reduced to 15-20 again Dr. gave me Taxim-o (200) for five days .but my pain didnt stopped im having severe pain in left side of the abdomen.and now after a month i just did my urine test my pus cell increased to 150-180 /hpf. Dr. suggested for Urine Culture test. but i will getmy report after days so till that report comes should i continue to take any antibiotic.please suggest me.Regardsmrs. shaikh\",\n",
    "    \"My 4 month old baby has a purple/reddish lump on her mid back that seems to be getting larger. Her doctor said it could be a platelet issue, I cant remember the term she used, and that we would watch it closely. Do you know what the doctor is talking about and should I get another opinion??\",\n",
    "    \"Hi! I am 5 wks. pregnant. I have a sluggish gallbladder, output of 27% , was to see a surgeon next week about having it removed until i found out i was pregnant. I am now having frequent loose stools. they almost appear oily or fatty.... greenish/brownish... not sure if its from the pregnancy or i guess my fear is that the gallbladder problem has created havoc on my pancreas and im freaking out\",\n",
    "    \"Hi, Im 29 yrs old and married for 6 yrs and not yet conceived at all. Had been in treatment from the 8th month of my marriage and took breaks too. GG, had been there for almost 2 yrs with laproscopy and 5 unsuccessful IUIs done. And 2 IUIs at Prashant multi speciality hospitals, which of first happened to be weakly positive. My problem is there is no diagnosis of what my problem is. My husbands count n motility is normal. My laprscopic n follicular studies give clear positive results. Inspite i have not conceived. Really wondering to know why we have to do IVF. I have a perfect 28 days cycle. My BMI is 29(overweight) and from novemeber 2010 have been identified thyroid too. Could there be anything like egg doesnt release? What to do if so? or egg release but too thick for the sperm to penetrate? what could be the reason? What to do now?\",\n",
    "    \"I have a tooth that was worked on 6 months ago.. they took my grey cavity out and filled it w a white one and also protected it w something.... they spent awhile on it. months later it was infected, so I took anti biotic... only bothered me a few times after minimal compared to b4 antibiotic... Now say 4 months I have a pimple like bubble on the side of my tooth... Is this conhhenry1978cerns to me suggestion I need a root canal??\",\n",
    "    \"Our 9 yr old boy has some issues with his running. His main issue is very tight hamstrings, along with weak hips. He wears orthotics and has been to PT as well as working with a running coach to help his bio mechanics. Things have improved apart from the hamstrings which have refused to loosen. Our PT mentioned mild Tethered Cord as an option, do you think this could be a possibility. He is a big guy, already 5ft and plays soccer, BB and tennis. Thanks Phil.\",\n",
    "    \"Hello. I am 24 years old. When I was in Second grade I got Hepatitis A. So I was between the age of 7-9. Is it still in my system after that many years? If I ever have children is there a possibility they will have it? Thanks for your time. Hope to hear from you soon.\",\n",
    "    \"Thank you; I tripped over a paving slab on 3rd May and fell forward flat on the ground, hitting my chin and my left knee particularly. The knee was never swollen but was very bruised. The leg was sore to walk on but gradually got better until last week when I had a difficult drive to work owing to heavy traffic. After that my knee became noticeably more sore (though not extreme pain) and since then it has got worse again. No muscular pain, swelling or bruising but it gets progressively painful if I try to walk and if I touch around (as opposed to upon) the kneecap it stings. I now can t really walk or drive and am off work. Apologies for the lengthy e-mail. I would appreciate your advice.\",\n",
    "    \"I have a feeling of a lump or something in my chest.squeezing across the mid section. plus trouble catching my breath sometimes,also a swishing noise in my chest to my head. after the squeezing and swishing I get a headache and my chest feels like I have been exercising. what is happing to me?\",\n",
    "    \"Hello I have a lump in the centre on the roof of my mouth. It has been there for almost 10 years. It becomes swollen, irritated and itchy for periods of time (days to weeks) and then settles down again, only to come back a week or so later. It feels like it is related to my allergies (eye conjunctivitis ). I did see an ENT specialist about 6 years ago. He told me it was just some dermatitis . What I really need is for someone to tell me how I can get some relief. It is very uncomfortable.\",\n",
    "    \"Hi, may I answer your health queries right now ? Please type your query here... I went to the doctor because of skipped heart beats, only lasting a second, which causes me to cough. Just didnt feel right. At the office my blood pressure was 169/92 which is 50 pts up for me, ekg turned out ok. He did chest xray and blood work. Waiting for results and appt. for echocardiogram. Heart feels like it beats a lot stronger.\",\n",
    "    \"Im 54 year old female, dont smoke, about 30 pounds overweight, my blood pressure typically is around, 128 over 80-something. About 18 months ago I had a chest pain that started in what felt like my stomach and spread across my chest, it was sharp and lasted a few minutes. I never had another until recently, now I get them a couple times a week. they feel like they start under my left breast and spread across both breasts and a feeling that I need to burp comes up into my throat, but I dont burp. Sometimes, it moves into my jaw. Once its gone, I feel fine. What do you think?\",\n",
    "    \"hellow... req u pls advise best gynecologist... five yrs has been passed we are unable to obtained one child.. in starting pregnancy was ok but after one Abortion we hv got serious prob. now we hv tried more even take consultancy with many gynecologist but unable to get pregnancy... pls help me and advise if Abortion is main reason not to getting pregnant ... ???\"\n",
    "]\n",
    "\n",
    "doctor_answers = [\n",
    "    \"Thanks for posting your query to Chat Doctor. After going through your history, I want to assure you not to get worried about it. White spots in oral cavity can occur due to many reasons which can only be told after proper visual examination. Do you have any other skin problem as sometimes these spots may be related to other systemic conditions? I would suggest you to visit a dentist and if needed a dermatologist for proper examination and treatment. Hope my answer will help you.\",\n",
    "    \"Hi... Thank you for consulting in Chat Doctor. This is called evening colic and is quite common in this age group. This happens when the baby sucks at the breast very fast and in eagerness to Chat Doctor. Unless the air comes out like burping or flatus this discomfort will be there. Usually I don't advice any medicines for this. The best ways are proper burping and prone position with gentle back patting.\",\n",
    "    \"I understand your concerns. From the description, diagnosis may not be possible. But your son could be suffering from depression which can cause lethargy and excessive sleep. I would suggest consulting a psychologist without delay.\",\n",
    "    \"It seems you are suffering from seborrheic dermatitis which can lead to hair fall. Use medicated shampoos, avoid excessive oiling, and take supplements like biotin. This should help.\",\n",
    "    \"Furosemide is a diuretic and increased urination is expected. You should not stop it without consulting your cardiologist. Regular follow-up is important.\",\n",
    "    \"This is most likely a ganglion rather than a lipoma. The pain and heat suggest infection. Consult an orthopedic surgeon; antibiotics and imaging like MRI may be needed.\",\n",
    "    \"Your liver enzymes are elevated, indicating liver disease. Udiliv is appropriate. Follow a low-fat diet and do not worry excessively. Levels should normalize.\",\n",
    "    \"Lumps on the roof of the mouth are often benign but need examination. Sinus and throat symptoms may or may not be related. Please see your doctor.\",\n",
    "    \"Blood beta-HCG is more accurate than urine tests. If blood test is negative, pregnancy is unlikely. Ultrasound can be done if doubt persists.\",\n",
    "    \"In resistant anxiety cases, alternative therapies like NLP or specialized acupuncture may help. Lorazepam can help symptoms but long-term strategy should be discussed.\",\n",
    "    \"HI. This may be a very small hernia in the center which is missed by all. Another possibility is costo-chon Chat Doctor. Hard-like-pipe thing is suggestive of this. Needs the investigations on this ground and a good clinical examination one can find these, if the Doctor is aware of such rare things. Can you post further information as to\",\n",
    "    \"Hi, Welcome to Chat Doctor .com I am Chat Doctor. Mariano Into Bruno Mascaras. I have gone through your query with diligence and would like you to know that I am here to help you. Alcohol affects nerve shaving alcohol will delay the healing process please avoid alcohol till you recover from bells palsy Hope you found the answer helpful. If you need any clarification / have doubts / have additional questions / have follow-up questions, then please do not hesitate in asking again. I will be happy to answer your questions. In the future, for continuity of care, I encourage you to contact me directly in Chat Doctor at http\",\n",
    "    \"Hi, Thank you for posting your query. I have noted your nephews symptoms and diagnosis. The fitness for flying depends on the severity of injury, CT scan findings and patients clinical condition. The fact that your nephew did not require surgery suggests that the injury is not severe. If his clinical condition is good, he would be fit to fly. It would be useful if you can upload a copy of his CT scan report here. I hope my answer helps. Please get back if you have any follow-up queries or if you require any additional information. Wishing you good health, Chat Doctor. Ly/\",\n",
    "    \"Hi, Thank you for posting your query. I think what you mean is atherosclerosis, where the arteries supplying blood to the brain get narrowed and may result in stroke due to ischemia (lack of blood flow). The treatment includes aspirin and stain use. The common risk factors for the same include high BP, sugar, cholesterol and smoking. Controlling these risk factors would stop the disease progression and prevent the strokes. Best wishes, Chat Doctor.\",\n",
    "    \"Hi, Based on details your father had R) focal onset seizure with secondary generalization and loss of consciousness. Need to rule out L) cerebral hemisphere structural lesion. Since he had previous history of Triple bypass surgery risk of ischemic stroke producing seizure is high. Hence, dose of anti platelets should be increased after ruling out brain bleed. He also requires anti-epileptic Chat Doctor. Consult nearby neurologist for further plan and management\",\n",
    "    \"Thanks for your question on Chat Doctor. In my opinion, you should rule out cardiac and pulmonary causes first for your intermittent chest pain. So get done ECG to rule out heart related causes. Get done chest x-ray to rule out pleurisy (inflammation of pleura) and lung related causes. If everything is normal then mostly you have anxiety and related chest discomfort. So better to consult psychiatrist and get done counselling sessions. Try to identify stressors in your life and start working on it. Avoid stress and anxiety. Be relax and calm.\",\n",
    "    \"Hello dear user! I have gone through your query and understood your concerns! Thank you for sharing them on Chat Doctor. We can't be sure that these symptoms you are experiencing now indicate heart failure without doing some examinations. Usually swollen ankles and feet are found in heart congestive failure, but in these cases, feet and ankles are more swollen in the evening and less in the morning. Kidney problems, diabetes, thyroid problems etc., may lead to similar symptoms. So to determine the real cause of these concerns I would recommend you to do some examinations to let us know more about your health.- Blood pressure monitoring-Blood sugar and lipids-Urine test, proteinuria- Liver enzymes, and kidney function indicators (creatinine, urea)- ECG-Heart ultrasound examination and cardiologist consultation doctor may ask for more examinations if he sees reasonable. After we get these results well be able to determine your condition and treat it accordingly. Feel free to ask us again on this website. I hope this answer was helpful to you! Please kindly rate it as helpful and write a short review about your experience with me! I would appreciate that a lot. Thank you and best regards! Chat Doctor.\",\n",
    "    \"Hi dear, I have gone through your question and understand your concerns. You are having recurrent urinary tract infection, which is most likely due to the calculi in the renal system. You should get active treatment for this infection, as it can cause preterm labor and delivery. You can continue taking plenty of fluids and oral antibiotics till the final culture report comes. Further management should be done accordingly. Hope you found the answer helpful. Wishing you good health. Regards Chat Doctor.\",\n",
    "    \"Hi, thanks for writing to Chat Doctor and sharing your babies health concerns with us! Well, If I were your treating Doctor for this case of the purple/reddish lump on the mid-back of baby, I would think of few possibilities\",\n",
    "    \"Hi and thank you so much for this query. I am so sorry to hear about what you are experiencing right now. A gall bladder problem can lead to diarrhea because food is not well digested as bile from the is very important in the digestion of fats. I will not particularly think that your pancreas has been damaged as you are not presenting with signs of pancreatitis which is often a pain. For now, stay relaxed and follow up with your doctors to figure out the exact cause and propose a treatment plan to you. I hope this ad Chat Doctor. Thank you so much for using our services, and please feel free to ask for clarifications if need be. I wish you the best of health.\",\n",
    "    \"Hi, I think you can go for few cycles of natural monitoring by ultrasound. You can track your follicles' growth by repeated ultrasound and when your follicles is more than 17 to 18 mm, take injection for rupturing the follicles. Be in contact with your husband every 2 to 3 days after your periods stop. Take progesterone for next 2 weeks. Do a urine pregnancy test at home after that. You can try like that for 3 cycles at least before going to IVF. Continue your thyroid medicine. Hope I have answered your question. Regards\",\n",
    "    \"Hi, Welcome to Chat Doctor forum, Your tooth which was filled earlier has got infection due to any residual caries or secondary caries. Due to caries, infection has reached the pulp and periapical abscess has formed. This pimple like bubble is due to abscess formed because pus needs a way to extrude itself. Consult a dentist for radio graphical examination done. Root canal treatment has to be done in this tooth. Take care\",\n",
    "    \"Hi, No. This doesn't seems like a case of tethered cord, as tethered cord has both motor and sensory signs and symptom and are usually progressive. This appears more like a case of cerebral palsy, tight hamstring with weak muscles is characteristic of hamstrings. Initial treatment is mainly through orthotics with adjuvant surgical procedures but to reach a diagnosis, a detailed physical examination is essential. As far as tight hamstrings is concerned, they can be lengthened by surgery. Take care. Hope I have answered your question. Let me know if I can assist you further.\",\n",
    "    \"Hi thanks for asking question. Let me clear your doubt dear... Hepatitis A spread in community by Eco oral route, means by contaminated food or water. So if you have this disease in childhood it is not spread to your child by you. Only if person take contaminated food or water by this virus then only hepatitis can occur. You have hepatitis A in childhood. So at that time protective antibody form in your system and protect you for many years. But virus cannot activate right now as it is already 10 years!! I hope I have solved your concern. Take care. Chat Doctor.\",\n",
    "    \"Brief Answer\",\n",
    "    \"Hi. I can understand your concern. Chest discomfort is commonly seen in bronchitis and lung infection. Since your chest x-ray is normal, no need to worry about lung infection. Possibility of bronchitis is more in your case. So better to consult pulmonologist and get done clinical examination of respiratory system and PFT (Pulmonary Function Test). PFT is needed for the diagnosis of bronchitis. It will also tell you about severity of the disease and treatment of bronchitis is based on severity only. You may need inhaled bronchodilators and inhaled corticosteroid (ICS)Don't worry, you will be alright. Hope I have solved your query. Wish you good health. Thanks.\",\n",
    "    \"Hi Evan, The problem you are describing can be associated with the allergy and with the sinus. If you are having some sort of sinusitis which is related with the nose sinuses infection or gallery, this can present as the problem which you are facing with. Allergic sinusitis is a chronic problem and is mostly because of some allergic substance and this can lead to a chronic condition. I would suggest you to consult some ENT surgeon regarding this problem and after proper history and examination and if required some investigation, it can be confirmed whether this is some sort of allergic problem or something different. Thanks.\",\n",
    "    \"Hello! Welcome and thank you for asking on Chat Doctor! I understand your concern and would explain that these skipped heart beats could be related to a cardiac arrhythmia. For this reason, I would recommend performing further tests\",\n",
    "    \"Hi There After going through your query I understand your concern. I would like to tell you that possibilities of acid Reflux/HERD more than a heart disease is there if you don't get breathless, palpitation with chest pain. It's advisable for you to avoid junk and spicy food to get relief and can use over the counter antacids also. Also get an ESG and Echocardiography done as a routine cardiac check up. Hopefully this will answer your query. Kind Regards Chat Doctor.\",\n",
    "    \"Hello and welcome to Chat Doctor, Abortion is not the cause of failure to conceive subsequently. Inability to conceive has many reasons.First, you have identified those days in your menstrual cycle when the chances of conception are maximum i.e. during ovulation. The period of ovulation can be determined by basal body temperature and changes in the cervical mucus. If conception does not take place even after taking care of the ovulation period, you need to get some investigations done. In your case, complete examination of the reproductive tract - ultrasonography and/ or hysterosalpingography, hormonal levels -estrogens, FSH and LH levels and follicular sac. In case of your husband, semen analysis should be under-taken. These are some of the investigations which will let your gynecologist know the cause of inability to conceive and thus plan management. Thanks and take care Chat Doctor.\"\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# QUANTIZATION\n",
    "# ----------------------------\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# TOKENIZER\n",
    "# ----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# INFERENCE FUNCTION\n",
    "# ----------------------------\n",
    "def run_inference(model, query):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,            # детерминированный режим для воспроизводимости\n",
    "            temperature=0.7,            # при do_sample=False не учитывается\n",
    "            top_p=0.95,                 # при do_sample=False не учитывается\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated = outputs[:, inputs.shape[1]:]\n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD MODELS\n",
    "# ----------------------------\n",
    "print(\"Loading BASE model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(\"\\nLoading LoRA model...\")\n",
    "base_for_lora = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    base_for_lora,\n",
    "    adapter_path,\n",
    ")\n",
    "\n",
    "lora_model.eval()\n",
    "base_model.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# RUN COMPARISON\n",
    "# ----------------------------\n",
    "print(\"Тест адаптера, обученного на исходных данных\")\n",
    "\n",
    "for i in range(30):\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(f\"QA #{i+1}\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"\\nЗАПРОС ПОЛЬЗОВАТЕЛЯ:\")\n",
    "    print(queries[i])\n",
    "    print(\"\\nЭТАЛОННЫЙ ОТВЕТ ВРАЧА:\")\n",
    "    print(doctor_answers[i])\n",
    "    print(\"\\nОТВЕТ БАЗОВОЙ МОДЕЛИ:\")\n",
    "    print(run_inference(base_model, queries[i]))\n",
    "    print(\"\\nОТВЕТ МОДЕЛИ С АДАПТЕРОМ:\")\n",
    "    print(run_inference(lora_model, queries[i]))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAOGBuaKQKM3"
   },
   "source": [
    "# Обучение адаптера на очищенных данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "Bt3Cum8kalMu",
    "outputId": "26ba7b48-8453-4257-9238-5b9f22ceb793"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1d79c520-2912-4912-a917-8603edefc7ed\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1d79c520-2912-4912-a917-8603edefc7ed\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Doctor_V2_QLoRA_1000_split.csv to Doctor_V2_QLoRA_1000_split.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Загрузка файла с локального ПК\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "KNDByOP1QKo7",
    "outputId": "d261015a-8b31-47cb-a731-aaf11147d684"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32307,\n        \"min\": 101,\n        \"max\": 112047,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          54371,\n          92450,\n          15850\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"gud day doc i have a question regarding my health ive been married for 4 years but not havent a baby yet.., i went to my genecology she examine me my pelvic ,she found out that i have a polycystic at right ovary and follicle monitoring..,question? 1)is that a capability to get pregnant?2)what is the medicine that i have to take 3)how months ive been waiting os that im pregnant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_v21\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Evaluation of difficulty conceiving focuses on whether infertility is primary or secondary, depending on whether you have ever been pregnant.\\nThis distinction affects diagnostic and management approaches.\\nIt is also important to characterize the type of ovarian cyst, as functional cysts, persistent organic cysts, and polycystic ovarian disease have different implications for fertility and treatment.\\nA consultation with an infertility specialist for thorough clinical evaluation and appropriate laboratory and imaging studies is recommended.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f426d7bb-c0d3-4786-a733-a8bfedd2424f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output_v21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53582</td>\n",
       "      <td>You are a licensed medical doctor. Respond in ...</td>\n",
       "      <td>my friend is currently in the hospital because...</td>\n",
       "      <td>Based on the limited history provided, a defin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f426d7bb-c0d3-4786-a733-a8bfedd2424f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f426d7bb-c0d3-4786-a733-a8bfedd2424f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f426d7bb-c0d3-4786-a733-a8bfedd2424f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0                                        instruction  \\\n",
       "0       53582  You are a licensed medical doctor. Respond in ...   \n",
       "\n",
       "                                               input  \\\n",
       "0  my friend is currently in the hospital because...   \n",
       "\n",
       "                                          output_v21  \n",
       "0  Based on the limited history provided, a defin...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Doctor_V2_QLoRA_1000_split.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_JwryeLQYqr",
    "outputId": "483fbf0b-078d-4901-deb8-a10c83901e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  1000 non-null   object\n",
      " 1   input        1000 non-null   object\n",
      " 2   output_v21   1000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "instruction_text = (\n",
    "    \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    ")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df[\"instruction\"] = instruction_text\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491,
     "referenced_widgets": [
      "e1537c9bd3f54c7abf4d7735c1a19112",
      "0ee6712b058249f38c37df02e3557b02",
      "8d316c0602504c4abb847c80811384c0",
      "d2b4a98bcd01481ea90ffbfc7a2efed4",
      "69dae016004d4652880316e42845558e",
      "a9f897ad487b4ff390be16199b6e9e5d",
      "35ca65f7241146879b154f9c60e4378b",
      "f3813c557c7e4a33b58a706e08a5564b",
      "10a2adc6994245daabab71c30416382c",
      "2657a7876c0b47a99f3b00d1c3816e6f",
      "d53d68fd5eae4e69920515cdbdcfbeff",
      "d8c199d2e2dc4057b841b839f770d6c6",
      "808fd56e965b499ebf301aa3d9a955f2",
      "05a11b94698e4b10a3abb1a169e9514d",
      "9492812c7fd0470ba31ffcbbf6eb5b26",
      "27424129dbc34f22a2ae55bc690b74bb",
      "b9f8301cb6af441795186ce83bab066a",
      "55d834d794944aeebcf66fb85312ef75",
      "c788ecf267d74697aa5331bca94a67d3",
      "bf54e52c3c504e8da8ba4d4eab751237",
      "6ace0d3beb5c48be9ed7b5cde6d9124e",
      "f36968b0c7784d219124bbb62d708da0",
      "e502dcc3dca84d0fb8dbb1da197321ea",
      "d5fcf742d60042c2b909342a99629b97",
      "caa8f91025ce400a9bdb7399206dd50e",
      "6437458743ae40db890a722a8d4cf49f",
      "73c728cdf1a644eb90681117113cf6e4",
      "85af7b7eb5c548e490e13c19254fc0e5",
      "cd23202986114cf3b30edfb58ec5ea6e",
      "a06bf63967774e428fa0bfbe2e319ce0",
      "af5ec921b509444e8ac750cb6b31658e",
      "025fc13bed004021986ed8ab94fb74ef",
      "07a455b5878c47ebbdce955dd0c39a6f",
      "6d75e1e7d1c445bb9708c5f025fd75aa",
      "911c542845554d9a9e145c02855a6598",
      "fb546dda98ff421b9a2f0dcdedcfd695",
      "a3a5942a65f24d9099a00f8649868905",
      "ceed7cdd62e2465e84066859219d0b38",
      "62093e18ef384cf88c6af9d3f15c6b00",
      "8371b008fc6240ab8227f7b984c2402d",
      "7cbb0a402eb347ad90aa63de7a79b9c2",
      "7be11b70d8724eec8a6969e280c23816",
      "583aec85c2ec4731b0f56f3b025308a1",
      "a15bd9c19ca24329adf38a026130be87",
      "ca1338c97b6940dbbad810edcb39581b",
      "262cf837c2ef4ce0882a994118d3fcae",
      "e5b1696603f243dd9d6f976ab2d31593",
      "624581338d304182b8f84c73e783a080",
      "87f70bd3f8ad406fa6e63fa0f59100ef",
      "46bc3e5239664dc6b04587f4cfd46b61",
      "5de8696a500c49168ac41d70575314f5",
      "bd5cbbec36b8416983b99b6e1d0fd897",
      "f57ad08e679841f5be61cd73e145c970",
      "b7c17e591a9d4f5ab0fe5ec30a9c841d",
      "a70f4becf1824f3197e8ef61de28425a",
      "8cf3dc38641247e38638775b2545ba05",
      "2ba8994b64b94e08934f348fefae7857",
      "abc5a12a30f74c6ba952913858c5c7e6",
      "8f73bf26a0914614b3a9229ab58bca18",
      "23620cd6f85a45e7b3974db8c66f412b",
      "933b9f006e804ca98d8848a8a5a8e5bf",
      "60363ffc2dd340ee8403be0b580f7448",
      "6f2d548a700242b88a844301ff0962ee",
      "db817811684f4ada868f7ebb2e23624a",
      "864f3047b92b4cfb8b8340cb2e355f1d",
      "99c3312913144df6b963df259652bbe4",
      "5edaf8e6c1f744609b61d6d237f0a3f1",
      "a4a5ae9460054f9ba58258384846b411",
      "5ed63594297042ff91eb284d747d4361",
      "6a46c46acca94e82b4a38819dff043fc",
      "45ae4546a7ef472c8c2ed4ca600656f3",
      "031cf4f04bff4518a1aaabbd755be895",
      "c530963010184bafa54092cf1c75310a",
      "c02e7f46cd6a4129a5064473b28e6ea3",
      "306c1249659745f5af79b18ec330ad94",
      "cf7e39279dee4245b23db54a6b8d8f51",
      "c25c3e756ea146af890790af1e079e72",
      "d5645de50d934bc9a713bfe908edc67c",
      "a31fce56247841cf8892c652dec761e6",
      "f54ce08003754e1095d1cadab870e9be",
      "83c841f806d746f192e622bb29e49e0b",
      "5010aceafda048d1837c86684e295837",
      "360dc27559f44e93b131e21030c83cb6",
      "cb504f5b0b1d44f59c781cdd98a6c2ec",
      "28e87bf914534c71899e0167fe9f6b3d",
      "60320bf50bc549889b2a2e8d676f0c89",
      "ca229266f84a46b5a3fe534137a8bdc0",
      "d0a89d66d9eb4cc0a28b3fce94f59959",
      "5437ef4833ee42dbbe9125ff5fb9f8e0",
      "63125f9a5bc34e97b3f7e5fee867bc43",
      "fd17ae5c22714376bc30a9e19f6bf4e1",
      "22194194dd1e44eeb3d9769bbaf2806b",
      "503696e915e2415eb857206ef085944c",
      "e0f0dc00d65349b997b49e878d3ebdc3",
      "f7f1f7d8ce3945d2bf7e1c335638f75b",
      "a538a03513bf41c9a001137d21698845",
      "f8d2dccc12d34454a2f0c359e03bc4dd",
      "2f2cf1e056ac44a7a6c8f955c6e2aee5",
      "52c091262e2b4a5599a74c84f9422835",
      "f92b6d0bd97b4be29fcb1da5b1ce5e7e",
      "49134671e5dd475aab66a0ed47f31b93",
      "fb874ddb3bff4cf3ac86b060d8b5f852",
      "4d341e6009df4b8890184711e80b14d5",
      "28a0837e772d4a17b1f347bd04d040ff",
      "a0b91616e4f846e8ae55bd818741a92e",
      "3661c4861a5d4e899b42fb15f276bb17",
      "8cf91519527642958bbd07e851f3020c",
      "fd83fc3b271749278cab57636f4506e4",
      "137370f4e59c480cbe2fcf5618596fb0",
      "eb6197dc3efb4d30859fc5b6c0293f24",
      "88ea06d8b0554fffbfc7528ac7dfa52d",
      "6d24b0ade2a14811b39b5d223a7ef881",
      "1259c8f6e69248a6bd6a49d2eb3fbaea",
      "07aa47e1d21e4746af0cf8a91ffc9553",
      "4063934fee044c90b7033243d3d37dbd",
      "2e72590861874888a2d701fdc503d4c3",
      "e3eb57a658034e4aa0c6404db2a759e0",
      "d1a10779a8a542e58f7827b831d0e633",
      "50c2bc34b5a74a64b736447c6c43cd1a",
      "61dc4f2417d04f089cf22d3eef3639c6",
      "eceb6998bd9e4926b5d75e875c33d9ef"
     ]
    },
    "id": "Z4IHt5_MQYoS",
    "outputId": "7c7aa288-6b64-4394-b0c0-02e3b2eb5cf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1537c9bd3f54c7abf4d7735c1a19112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c199d2e2dc4057b841b839f770d6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e502dcc3dca84d0fb8dbb1da197321ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d75e1e7d1c445bb9708c5f025fd75aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1338c97b6940dbbad810edcb39581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3dc38641247e38638775b2545ba05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edaf8e6c1f744609b61d6d237f0a3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5645de50d934bc9a713bfe908edc67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5437ef4833ee42dbbe9125ff5fb9f8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92b6d0bd97b4be29fcb1da5b1ce5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ea06d8b0554fffbfc7528ac7dfa52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # КРИТИЧНО\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b7e5dcb989194bed814b6aafba1f3f8d",
      "633b0750a98c431a85ddbd53a740a0c4",
      "16ddfe3168e747b3b0eacae6f638525a",
      "113c986122ef42a79d0ad26ace04ae99",
      "750eca9ca7584255813a412466e7f0b3",
      "0ca44171abb14964a6dded99338eda8c",
      "24806b7eb30140b99ab32bd01c5a671d",
      "60036629101c4934ab0169f534b2e524",
      "f2c60603b7ea4aaba7fbeb28cd32674e",
      "c8bd22be30554656afbe59fc4a26b3db",
      "6dee3a7072154223b59ccf405799b429"
     ]
    },
    "id": "_fznm__ZQYmN",
    "outputId": "a1614698-4f34-46e5-e0af-41bf794f5d1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e5dcb989194bed814b6aafba1f3f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def formatting_func(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": example[\"instruction\"]},\n",
    "        {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"output_v21\"]},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    return {\"text\": text}\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(\n",
    "    formatting_func,\n",
    "    remove_columns=dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_upBiJgmQYj4",
    "outputId": "7f2491fa-319b-4752-9bf8-7f6e770503a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 29,933,568 || all params: 3,115,872,256 || trainable%: 0.9607\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2bb8700ef66d4b1981832585c6f90b81",
      "cfb6716d15a7490285c1c384f95c0e65",
      "de23f13282f440fb817623167b1dbe28",
      "f770b81eff61455fb1ca75788d427cf6",
      "87b7137bc11547fa843e85a9ee079c5a",
      "e7a3f414c7e843da83c34daaf73c10c4",
      "e76409fb711e4e8a8f9809d8d918ccac",
      "5c959eed4b0745bb8b8c2fa23c5b6ce4",
      "d53411dfe69f4b168ce559dfa4b01e91",
      "5559021b09854362a2d59480d217b8cb",
      "af3324e2b1ed4779b640ff8bdf5a79db",
      "05e1170139a14763b5bfdf715699ebbf",
      "a022d116b526482aadd911919de17027",
      "b966767cb81a4a9f82c8c3befab48999",
      "c4d6b09db0c24d52b67d14467dfc5e6c",
      "9e9ac380e3a74560ba6e2cbeed8d63a3",
      "65367699fcaf45b9b003919bb331be6a",
      "d5c9aa1382d84014bcab0231fd61e4da",
      "0c37d76674ce4dacac700a55379a211d",
      "c53ca050c3194eb6a98bbc0e32035ac3",
      "b7ad6000fbff4221bcdae0c475eafc09",
      "25756fd4028b410cabaa480ed0c66d70",
      "eb16a78c2b304b2e8ad26a6a10368480",
      "ed713fc7f50a4bf98d102132d2ba7bd7",
      "e85f9fbbb1244f6888c035de9628e3ad",
      "4e87b8c1a42f488fa52ab530d7aab043",
      "ee1906036ee7403a82bc28ad07539e91",
      "82a3cabc772c4bf3abff0ff698835915",
      "738c6737164b4c62a2fa22d466f4fd3d",
      "94d8ad49cbfd4f4fbe25a691000d7a12",
      "c61154b75d31441ca85c6cace29e6b90",
      "eab7734b404549978ec9a79ce900ee45",
      "80ff27bc786343d4945df7cc75b1328f"
     ]
    },
    "id": "mKA_AS58QYhh",
    "outputId": "3973525c-a983-401b-df83-324e7ad0ea94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb8700ef66d4b1981832585c6f90b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e1170139a14763b5bfdf715699ebbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb16a78c2b304b2e8ad26a6a10368480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/250 06:31 < 09:11, 0.26 it/s, Epoch 0.42/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.237900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.147200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 15:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.237900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.070300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.064400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./Clean_Qwen3B_QLoRA/adapter/tokenizer_config.json',\n",
       " './Clean_Qwen3B_QLoRA/adapter/special_tokens_map.json',\n",
       " './Clean_Qwen3B_QLoRA/adapter/chat_template.jinja',\n",
       " './Clean_Qwen3B_QLoRA/adapter/vocab.json',\n",
       " './Clean_Qwen3B_QLoRA/adapter/merges.txt',\n",
       " './Clean_Qwen3B_QLoRA/adapter/added_tokens.json',\n",
       " './Clean_Qwen3B_QLoRA/adapter/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./Clean_Qwen3B_QLoRA\",\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    optim=\"adamw_torch\",        # ← безопасный оптимизатор\n",
    "    learning_rate=9e-5,         # Сделал чуть ниже среднего\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    fp16=False,                 # ← ВАЖНО\n",
    "    bf16=False,                 # ← ВАЖНО\n",
    "    max_grad_norm=0.0,          # ← КРИТИЧНО (иначе падение)\n",
    "\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length=1024,\n",
    "    packing=False,\n",
    "\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=sft_config,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# сохранить ТОЛЬКО обученный LoRA-адаптер\n",
    "model.eval()\n",
    "\n",
    "adapter_path = \"./Clean_Qwen3B_QLoRA/adapter\"\n",
    "model.save_pretrained(adapter_path)\n",
    "tokenizer.save_pretrained(adapter_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YTYbZpMhC7H"
   },
   "source": [
    "# Инференс для сравнения BaseLine Модели и двух адаптеров QLoRA. Продолжение для адаптера, обученного на очищенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sigOj9gtimWw",
    "outputId": "91f08243-089e-41f2-dfec-10bb41416bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned_DATA_QLoRA успешно добавлен.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path(\"QLoRA.json\")\n",
    "OUTPUT_PATH = Path(\"QLoRA.json\")  # можно заменить на другой файл при необходимости\n",
    "\n",
    "CLEANED_TEMPLATE = {\n",
    "    \"text\": \"\",\n",
    "    \"latency_sec\": None,\n",
    "    \"prompt_tokens\": None,\n",
    "    \"generated_tokens\": None,\n",
    "    \"total_tokens\": None,\n",
    "    \"timestamp_utc\": \"\"\n",
    "}\n",
    "\n",
    "def main():\n",
    "    if not INPUT_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Файл не найден: {INPUT_PATH}\")\n",
    "\n",
    "    with INPUT_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    modified = False\n",
    "\n",
    "    for sample_id, sample in data.items():\n",
    "        if not isinstance(sample, dict):\n",
    "            continue\n",
    "\n",
    "        if \"RAW_DATA_QLoRA\" in sample:\n",
    "            if \"Cleaned_DATA_QLoRA\" not in sample:\n",
    "                sample[\"Cleaned_DATA_QLoRA\"] = CLEANED_TEMPLATE.copy()\n",
    "                modified = True\n",
    "\n",
    "    if modified:\n",
    "        with OUTPUT_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(\"✅ Cleaned_DATA_QLoRA успешно добавлен.\")\n",
    "    else:\n",
    "        print(\"ℹ️ Изменений не требуется — ключ уже существует.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 715,
     "referenced_widgets": [
      "19826dacb72a421a8b65761aae741831",
      "8add65be41144008917e2b3a858e93f4",
      "7e37ca297e4e4c9cb78cf210a7a509c8",
      "b2b6e0f1d6da4c57a7e68748cd7044d6",
      "190e94702f254773a5e93519b9818a8a",
      "48a3f1b1ceec4206b2e09dbef0cfde34",
      "92fef849cca74a4aaf92186d82cf37ed",
      "dd43f24e6cc04054903d2b23bf1a828f",
      "20f2a558e2d74301bce8e15045c9ce52",
      "afcf6ca21e834314b7c22a8562759ce2",
      "6b5d538b97994a58bf69a56a7a8ea783"
     ]
    },
    "id": "Ta4iZj4vQYck",
    "outputId": "b815acf0-19fc-4414-9059-70233217afda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19826dacb72a421a8b65761aae741831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cleaned LoRA] QA #1\n",
      "[Cleaned LoRA] QA #2\n",
      "[Cleaned LoRA] QA #3\n",
      "[Cleaned LoRA] QA #4\n",
      "[Cleaned LoRA] QA #5\n",
      "[Cleaned LoRA] QA #6\n",
      "[Cleaned LoRA] QA #7\n",
      "[Cleaned LoRA] QA #8\n",
      "[Cleaned LoRA] QA #9\n",
      "[Cleaned LoRA] QA #10\n",
      "[Cleaned LoRA] QA #11\n",
      "[Cleaned LoRA] QA #12\n",
      "[Cleaned LoRA] QA #13\n",
      "[Cleaned LoRA] QA #14\n",
      "[Cleaned LoRA] QA #15\n",
      "[Cleaned LoRA] QA #16\n",
      "[Cleaned LoRA] QA #17\n",
      "[Cleaned LoRA] QA #18\n",
      "[Cleaned LoRA] QA #19\n",
      "[Cleaned LoRA] QA #20\n",
      "[Cleaned LoRA] QA #21\n",
      "[Cleaned LoRA] QA #22\n",
      "[Cleaned LoRA] QA #23\n",
      "[Cleaned LoRA] QA #24\n",
      "[Cleaned LoRA] QA #25\n",
      "[Cleaned LoRA] QA #26\n",
      "[Cleaned LoRA] QA #27\n",
      "[Cleaned LoRA] QA #28\n",
      "[Cleaned LoRA] QA #29\n",
      "[Cleaned LoRA] QA #30\n",
      "Cleaned LoRA inference completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "MODEL_ID = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "ADAPTER_PATH = \"./Clean_Qwen3B_QLoRA/adapter\"\n",
    "JSON_PATH = \"./QLoRA.json\"\n",
    "\n",
    "DTYPE = torch.float16\n",
    "\n",
    "# ----------------------------\n",
    "# QUANTIZATION\n",
    "# ----------------------------\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=DTYPE,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# TOKENIZER\n",
    "# ----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# INFERENCE FUNCTION\n",
    "# ----------------------------\n",
    "def run_inference(model, query: str) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a licensed medical doctor. Respond in a professional, neutral, and explanatory tone.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id)\n",
    "    prompt_tokens = inputs.shape[1]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    latency = time.perf_counter() - start_time\n",
    "\n",
    "    generated_tokens = outputs.shape[1] - prompt_tokens\n",
    "    total_tokens = outputs.shape[1]\n",
    "\n",
    "    generated = outputs[:, prompt_tokens:]\n",
    "    text = tokenizer.decode(generated[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"latency_sec\": round(latency, 4),\n",
    "        \"prompt_tokens\": int(prompt_tokens),\n",
    "        \"generated_tokens\": int(generated_tokens),\n",
    "        \"total_tokens\": int(total_tokens),\n",
    "        \"timestamp_utc\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD LoRA MODEL\n",
    "# ----------------------------\n",
    "print(\"Loading LoRA model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    ADAPTER_PATH,\n",
    ")\n",
    "lora_model.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD JSON\n",
    "# ----------------------------\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# LoRA INFERENCE LOOP\n",
    "# ----------------------------\n",
    "for key in sorted(results.keys(), key=lambda x: int(x)):\n",
    "    entry = results[key]\n",
    "\n",
    "    # 🔒 защита на случай кривых записей\n",
    "    if \"Cleaned_DATA_QLoRA\" not in entry:\n",
    "        continue\n",
    "\n",
    "    # ⏭ skip если уже есть результат\n",
    "    if entry[\"Cleaned_DATA_QLoRA\"].get(\"text\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"[Cleaned LoRA] QA #{key}\")\n",
    "\n",
    "    lora_out = run_inference(lora_model, entry[\"query\"])\n",
    "\n",
    "    # ✅ запись ТОЛЬКО в Cleaned_DATA_QLoRA\n",
    "    entry[\"Cleaned_DATA_QLoRA\"] = lora_out\n",
    "\n",
    "    # 💾 безопасный инкрементальный save\n",
    "    with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Cleaned LoRA inference completed.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "U3uCQp3JQg2G",
    "5cdAtuPpqI1w"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
